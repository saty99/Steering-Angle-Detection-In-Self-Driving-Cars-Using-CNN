{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36324\n",
      "36324 9082\n"
     ]
    }
   ],
   "source": [
    "import scipy.misc\n",
    "import random\n",
    "\n",
    "train_batch_pointer=0\n",
    "\n",
    "validation_batch_pointer=0\n",
    "\n",
    "from itertools import islice\n",
    "\n",
    "images=[]\n",
    "\n",
    "angles=[]\n",
    "\n",
    "from scipy import pi\n",
    "\n",
    "txt=open(\"driving_dataset/driving_dataset/data.txt\")\n",
    "num_lines=sum(1 for line in open(\"driving_dataset/driving_dataset/data.txt\"))\n",
    "lines_slice=islice(txt,num_lines)\n",
    "\n",
    "for line in lines_slice:\n",
    "\timage,angle=line.strip().split()\n",
    "\timages.append(\"driving_dataset/driving_dataset/\"+image)\n",
    "\tangle=float(angle)*scipy.pi/180\n",
    "\tangles.append(angle)\n",
    "\n",
    "#time based split\n",
    "split_ratio=0.8\n",
    "split_up_to=int(num_lines*split_ratio)\n",
    "print(split_up_to)\n",
    "train_images=images[:split_up_to]\n",
    "train_angles=angles[:split_up_to]\n",
    "\n",
    "validation_images=images[split_up_to:]\n",
    "validation_angles=angles[split_up_to:]\n",
    "\n",
    "num_train_images=len(train_images)\n",
    "num_validation_images=len(validation_images)\n",
    "print(num_train_images,num_validation_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time took: 0:00:00.009006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saireddyavs\\Anaconda3\\envs\\gpuu\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\saireddyavs\\Anaconda3\\envs\\gpuu\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time took: 0:00:27.085960\n",
      "time took: 0:00:00.002992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saireddyavs\\Anaconda3\\envs\\gpuu\\lib\\site-packages\\ipykernel_launcher.py:34: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "C:\\Users\\saireddyavs\\Anaconda3\\envs\\gpuu\\lib\\site-packages\\ipykernel_launcher.py:34: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time took: 0:04:07.663471\n",
      "time took:: 0:02:05.606938\n"
     ]
    }
   ],
   "source": [
    "train_ang=[]\n",
    "import datetime  as dt\n",
    "start=dt.datetime.now()\n",
    "for i in range(0,36324):\n",
    "    train_ang.append([train_angles[i]])\n",
    "    \n",
    "print(\"time took:\",dt.datetime.now()-start)\n",
    "\n",
    "\n",
    "\n",
    "val_im=[]\n",
    "\n",
    "import datetime  as dt\n",
    "start=dt.datetime.now()\n",
    "for i in range(0,9082):\n",
    "    val_im.append(scipy.misc.imresize(scipy.misc.imread(validation_images[ i ])[-150:], [66, 200]) / 255.0)\n",
    "print(\"time took:\",dt.datetime.now()-start)\n",
    "\n",
    "\n",
    "\n",
    "val_ang=[]\n",
    "import datetime  as dt\n",
    "start=dt.datetime.now()\n",
    "for i in range(0,9082):\n",
    "    val_ang.append([validation_angles[i]])\n",
    "    \n",
    "print(\"time took:\",dt.datetime.now()-start)\n",
    "\n",
    "\n",
    "train_im=[]\n",
    "import datetime  as dt\n",
    "start=dt.datetime.now()\n",
    "for i in range(0,36324):\n",
    "    train_im.append(scipy.misc.imresize(scipy.misc.imread(train_images[ i ])[-150:], [66, 200]) / 255.0)\n",
    "    \n",
    "print(\"time took:\",dt.datetime.now()-start)\n",
    "\n",
    "\n",
    "start = dt.datetime.now()\n",
    "\n",
    "import numpy as np\n",
    "train_im=np.array(train_im)\n",
    "val_im=np.array(val_im)\n",
    "val_ang=np.array(val_ang)\n",
    "train_ang=np.array(train_ang)\n",
    "\n",
    "print(\"time took::\",dt.datetime.now()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\saireddyavs\\Anaconda3\\envs\\gpuu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\saireddyavs\\Anaconda3\\envs\\gpuu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 31, 98, 24)        1824      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 47, 36)        21636     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 22, 48)         43248     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 2, 10, 64)         27712     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               128100    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 227,621\n",
      "Trainable params: 227,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense,Flatten,Dropout,Conv2D\n",
    "from keras import backend as k\n",
    "from keras.initializers import TruncatedNormal,Constant\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(24, (5,5), strides=(2,2), activation=\"relu\",input_shape = (66,200,3) ))\n",
    "model.add(Conv2D(36, (5,5), strides=(2,2), activation=\"relu\" ))\n",
    "model.add(Conv2D(48, (5,5), strides=(2,2), activation=\"relu\" ))\n",
    "model.add(Conv2D(64, (3,3), strides=(2,2), activation=\"relu\" ))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(100))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\saireddyavs\\Anaconda3\\envs\\gpuu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 36324 samples, validate on 9082 samples\n",
      "Epoch 1/1000\n",
      "36324/36324 [==============================] - 82s 2ms/step - loss: 0.2644 - val_loss: 0.2032\n",
      "Epoch 2/1000\n",
      "36324/36324 [==============================] - 54s 1ms/step - loss: 0.2003 - val_loss: 0.2378\n",
      "Epoch 3/1000\n",
      "36324/36324 [==============================] - 45s 1ms/step - loss: 0.1396 - val_loss: 0.2635\n",
      "Epoch 4/1000\n",
      "36324/36324 [==============================] - 44s 1ms/step - loss: 0.0980 - val_loss: 0.3144\n",
      "Epoch 5/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0999 - val_loss: 0.2673\n",
      "Epoch 6/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0685 - val_loss: 0.2447\n",
      "Epoch 7/1000\n",
      "36324/36324 [==============================] - 43s 1ms/step - loss: 0.0644 - val_loss: 0.2194\n",
      "Epoch 8/1000\n",
      "36324/36324 [==============================] - 44s 1ms/step - loss: 0.0479 - val_loss: 0.2061\n",
      "Epoch 9/1000\n",
      "36324/36324 [==============================] - 43s 1ms/step - loss: 0.0434 - val_loss: 0.2217\n",
      "Epoch 10/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0417 - val_loss: 0.2521\n",
      "Epoch 11/1000\n",
      "36324/36324 [==============================] - 69s 2ms/step - loss: 0.0450 - val_loss: 0.1838\n",
      "Epoch 12/1000\n",
      "36324/36324 [==============================] - 48s 1ms/step - loss: 0.0389 - val_loss: 0.2038\n",
      "Epoch 13/1000\n",
      "36324/36324 [==============================] - 45s 1ms/step - loss: 0.0370 - val_loss: 0.2052\n",
      "Epoch 14/1000\n",
      "36324/36324 [==============================] - 44s 1ms/step - loss: 0.0337 - val_loss: 0.1985\n",
      "Epoch 15/1000\n",
      "36324/36324 [==============================] - 35s 971us/step - loss: 0.0293 - val_loss: 0.1913\n",
      "Epoch 16/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0293 - val_loss: 0.2178\n",
      "Epoch 17/1000\n",
      "36324/36324 [==============================] - 45s 1ms/step - loss: 0.0306 - val_loss: 0.2152\n",
      "Epoch 18/1000\n",
      "36324/36324 [==============================] - 49s 1ms/step - loss: 0.0260 - val_loss: 0.2168\n",
      "Epoch 19/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0250 - val_loss: 0.1901\n",
      "Epoch 20/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0253 - val_loss: 0.1903\n",
      "Epoch 21/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0292 - val_loss: 0.1740\n",
      "Epoch 22/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0230 - val_loss: 0.1663\n",
      "Epoch 23/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0254 - val_loss: 0.1863\n",
      "Epoch 24/1000\n",
      "36324/36324 [==============================] - 47s 1ms/step - loss: 0.0250 - val_loss: 0.1717\n",
      "Epoch 25/1000\n",
      "36324/36324 [==============================] - 54s 1ms/step - loss: 0.0234 - val_loss: 0.1809\n",
      "Epoch 26/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0267 - val_loss: 0.1992\n",
      "Epoch 27/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0237 - val_loss: 0.1748\n",
      "Epoch 28/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0245 - val_loss: 0.1797\n",
      "Epoch 29/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0229 - val_loss: 0.1858\n",
      "Epoch 30/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0208 - val_loss: 0.1982\n",
      "Epoch 31/1000\n",
      "36324/36324 [==============================] - 54s 1ms/step - loss: 0.0217 - val_loss: 0.1884\n",
      "Epoch 32/1000\n",
      "36324/36324 [==============================] - 56s 2ms/step - loss: 0.0237 - val_loss: 0.1774\n",
      "Epoch 33/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0227 - val_loss: 0.1713\n",
      "Epoch 34/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0204 - val_loss: 0.1702\n",
      "Epoch 35/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0224 - val_loss: 0.1822\n",
      "Epoch 36/1000\n",
      "36324/36324 [==============================] - 44s 1ms/step - loss: 0.0203 - val_loss: 0.2089\n",
      "Epoch 37/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0279 - val_loss: 0.1856\n",
      "Epoch 38/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0243 - val_loss: 0.2113\n",
      "Epoch 39/1000\n",
      "36324/36324 [==============================] - 48s 1ms/step - loss: 0.0233 - val_loss: 0.1705\n",
      "Epoch 40/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0203 - val_loss: 0.1857\n",
      "Epoch 41/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0249 - val_loss: 0.2020\n",
      "Epoch 42/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0231 - val_loss: 0.1793\n",
      "Epoch 43/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0188 - val_loss: 0.1733\n",
      "Epoch 44/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0195 - val_loss: 0.1795\n",
      "Epoch 45/1000\n",
      "36324/36324 [==============================] - 36s 1000us/step - loss: 0.0185 - val_loss: 0.1927\n",
      "Epoch 46/1000\n",
      "36324/36324 [==============================] - 43s 1ms/step - loss: 0.0191 - val_loss: 0.1684\n",
      "Epoch 47/1000\n",
      "36324/36324 [==============================] - 46s 1ms/step - loss: 0.0201 - val_loss: 0.1866\n",
      "Epoch 48/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0189 - val_loss: 0.1807\n",
      "Epoch 49/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0203 - val_loss: 0.1754\n",
      "Epoch 50/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0229 - val_loss: 0.1798\n",
      "Epoch 51/1000\n",
      "36324/36324 [==============================] - 34s 935us/step - loss: 0.0183 - val_loss: 0.1831\n",
      "Epoch 52/1000\n",
      "36324/36324 [==============================] - 35s 952us/step - loss: 0.0172 - val_loss: 0.1930\n",
      "Epoch 53/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0168 - val_loss: 0.1754\n",
      "Epoch 54/1000\n",
      "36324/36324 [==============================] - 45s 1ms/step - loss: 0.0171 - val_loss: 0.1910\n",
      "Epoch 55/1000\n",
      "36324/36324 [==============================] - 51s 1ms/step - loss: 0.0179 - val_loss: 0.1803\n",
      "Epoch 56/1000\n",
      "36324/36324 [==============================] - 44s 1ms/step - loss: 0.0165 - val_loss: 0.1890\n",
      "Epoch 57/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0197 - val_loss: 0.1897\n",
      "Epoch 58/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0199 - val_loss: 0.1761\n",
      "Epoch 59/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0178 - val_loss: 0.1962\n",
      "Epoch 60/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0169 - val_loss: 0.1949\n",
      "Epoch 61/1000\n",
      "36324/36324 [==============================] - 45s 1ms/step - loss: 0.0173 - val_loss: 0.1708\n",
      "Epoch 62/1000\n",
      "36324/36324 [==============================] - 46s 1ms/step - loss: 0.0159 - val_loss: 0.1700\n",
      "Epoch 63/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0151 - val_loss: 0.1734\n",
      "Epoch 64/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0146 - val_loss: 0.1771\n",
      "Epoch 65/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0150 - val_loss: 0.1909\n",
      "Epoch 66/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0166 - val_loss: 0.2004\n",
      "Epoch 67/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0154 - val_loss: 0.1709\n",
      "Epoch 68/1000\n",
      "36324/36324 [==============================] - 36s 1ms/step - loss: 0.0160 - val_loss: 0.1764\n",
      "Epoch 69/1000\n",
      "36324/36324 [==============================] - 44s 1ms/step - loss: 0.0164 - val_loss: 0.1774\n",
      "Epoch 70/1000\n",
      "36324/36324 [==============================] - 50s 1ms/step - loss: 0.0159 - val_loss: 0.1780\n",
      "Epoch 71/1000\n",
      "36324/36324 [==============================] - 46s 1ms/step - loss: 0.0163 - val_loss: 0.2000\n",
      "Epoch 72/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0167 - val_loss: 0.1847\n",
      "Epoch 73/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0179 - val_loss: 0.1874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0159 - val_loss: 0.2215\n",
      "Epoch 75/1000\n",
      "36324/36324 [==============================] - 73s 2ms/step - loss: 0.0154 - val_loss: 0.1859\n",
      "Epoch 76/1000\n",
      "36324/36324 [==============================] - 99s 3ms/step - loss: 0.0151 - val_loss: 0.1730\n",
      "Epoch 77/1000\n",
      "36324/36324 [==============================] - 80s 2ms/step - loss: 0.0150 - val_loss: 0.1961\n",
      "Epoch 78/1000\n",
      "36324/36324 [==============================] - 80s 2ms/step - loss: 0.0144 - val_loss: 0.1761\n",
      "Epoch 79/1000\n",
      "36324/36324 [==============================] - 84s 2ms/step - loss: 0.0151 - val_loss: 0.1686\n",
      "Epoch 80/1000\n",
      "36324/36324 [==============================] - 83s 2ms/step - loss: 0.0169 - val_loss: 0.2059\n",
      "Epoch 81/1000\n",
      "36324/36324 [==============================] - 77s 2ms/step - loss: 0.0160 - val_loss: 0.2109\n",
      "Epoch 82/1000\n",
      "36324/36324 [==============================] - 83s 2ms/step - loss: 0.0159 - val_loss: 0.1910\n",
      "Epoch 83/1000\n",
      "36324/36324 [==============================] - 186s 5ms/step - loss: 0.0160 - val_loss: 0.1661\n",
      "Epoch 84/1000\n",
      "36324/36324 [==============================] - 88s 2ms/step - loss: 0.0155 - val_loss: 0.1832\n",
      "Epoch 85/1000\n",
      "36324/36324 [==============================] - 77s 2ms/step - loss: 0.0157 - val_loss: 0.1800\n",
      "Epoch 86/1000\n",
      "36324/36324 [==============================] - 73s 2ms/step - loss: 0.0139 - val_loss: 0.1737\n",
      "Epoch 87/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0142 - val_loss: 0.1823\n",
      "Epoch 88/1000\n",
      "36324/36324 [==============================] - 36s 990us/step - loss: 0.0143 - val_loss: 0.1839\n",
      "Epoch 89/1000\n",
      "36324/36324 [==============================] - 34s 928us/step - loss: 0.0136 - val_loss: 0.1840\n",
      "Epoch 90/1000\n",
      "36324/36324 [==============================] - 36s 1ms/step - loss: 0.0162 - val_loss: 0.1736\n",
      "Epoch 91/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0147 - val_loss: 0.1685\n",
      "Epoch 92/1000\n",
      "36324/36324 [==============================] - 60s 2ms/step - loss: 0.0161 - val_loss: 0.1968\n",
      "Epoch 93/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0156 - val_loss: 0.1746\n",
      "Epoch 94/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0150 - val_loss: 0.1757\n",
      "Epoch 95/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0163 - val_loss: 0.1859\n",
      "Epoch 96/1000\n",
      "36324/36324 [==============================] - 35s 966us/step - loss: 0.0146 - val_loss: 0.1852\n",
      "Epoch 97/1000\n",
      "36324/36324 [==============================] - 34s 945us/step - loss: 0.0134 - val_loss: 0.1731\n",
      "Epoch 98/1000\n",
      "36324/36324 [==============================] - 35s 967us/step - loss: 0.0138 - val_loss: 0.1703\n",
      "Epoch 99/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0129 - val_loss: 0.2007\n",
      "Epoch 100/1000\n",
      "cooling down to decrease CPU tempereture\n",
      "36324/36324 [==============================] - 355s 10ms/step - loss: 0.0153 - val_loss: 0.1751\n",
      "Epoch 101/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0183 - val_loss: 0.1789\n",
      "Epoch 102/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0185 - val_loss: 0.1954\n",
      "Epoch 103/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0142 - val_loss: 0.1788\n",
      "Epoch 104/1000\n",
      "36324/36324 [==============================] - 54s 1ms/step - loss: 0.0140 - val_loss: 0.1818\n",
      "Epoch 105/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0143 - val_loss: 0.1828\n",
      "Epoch 106/1000\n",
      "36324/36324 [==============================] - 36s 978us/step - loss: 0.0135 - val_loss: 0.2010\n",
      "Epoch 107/1000\n",
      "36324/36324 [==============================] - 34s 948us/step - loss: 0.0141 - val_loss: 0.1825\n",
      "Epoch 108/1000\n",
      "36324/36324 [==============================] - 34s 932us/step - loss: 0.0134 - val_loss: 0.1769\n",
      "Epoch 109/1000\n",
      "36324/36324 [==============================] - 44s 1ms/step - loss: 0.0150 - val_loss: 0.1762\n",
      "Epoch 110/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0142 - val_loss: 0.1714\n",
      "Epoch 111/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0147 - val_loss: 0.1831\n",
      "Epoch 112/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0127 - val_loss: 0.1806\n",
      "Epoch 113/1000\n",
      "36324/36324 [==============================] - 43s 1ms/step - loss: 0.0129 - val_loss: 0.1965\n",
      "Epoch 114/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0130 - val_loss: 0.1776\n",
      "Epoch 115/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0128 - val_loss: 0.1684\n",
      "Epoch 116/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0130 - val_loss: 0.1768\n",
      "Epoch 117/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0141 - val_loss: 0.1738\n",
      "Epoch 118/1000\n",
      "36324/36324 [==============================] - 36s 989us/step - loss: 0.0127 - val_loss: 0.1740\n",
      "Epoch 119/1000\n",
      "36324/36324 [==============================] - 33s 914us/step - loss: 0.0130 - val_loss: 0.1707\n",
      "Epoch 120/1000\n",
      "36324/36324 [==============================] - 33s 904us/step - loss: 0.0126 - val_loss: 0.1676\n",
      "Epoch 121/1000\n",
      "36324/36324 [==============================] - 34s 936us/step - loss: 0.0126 - val_loss: 0.1699\n",
      "Epoch 122/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0136 - val_loss: 0.1711\n",
      "Epoch 123/1000\n",
      "36324/36324 [==============================] - 46s 1ms/step - loss: 0.0137 - val_loss: 0.1666\n",
      "Epoch 124/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0127 - val_loss: 0.1869\n",
      "Epoch 125/1000\n",
      "36324/36324 [==============================] - 36s 995us/step - loss: 0.0138 - val_loss: 0.1764\n",
      "Epoch 126/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0127 - val_loss: 0.1755\n",
      "Epoch 127/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0137 - val_loss: 0.1941\n",
      "Epoch 128/1000\n",
      "36324/36324 [==============================] - 36s 987us/step - loss: 0.0168 - val_loss: 0.1957\n",
      "Epoch 129/1000\n",
      "36324/36324 [==============================] - 33s 914us/step - loss: 0.0128 - val_loss: 0.1748\n",
      "Epoch 130/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0122 - val_loss: 0.1684\n",
      "Epoch 131/1000\n",
      "36324/36324 [==============================] - 45s 1ms/step - loss: 0.0119 - val_loss: 0.1701\n",
      "Epoch 132/1000\n",
      "36324/36324 [==============================] - 35s 975us/step - loss: 0.0121 - val_loss: 0.1718\n",
      "Epoch 133/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0115 - val_loss: 0.1803\n",
      "Epoch 134/1000\n",
      "36324/36324 [==============================] - 34s 947us/step - loss: 0.0118 - val_loss: 0.1742\n",
      "Epoch 135/1000\n",
      "36324/36324 [==============================] - 36s 993us/step - loss: 0.0130 - val_loss: 0.1685\n",
      "Epoch 136/1000\n",
      "36324/36324 [==============================] - 36s 982us/step - loss: 0.0132 - val_loss: 0.1749\n",
      "Epoch 137/1000\n",
      "36324/36324 [==============================] - 36s 981us/step - loss: 0.0142 - val_loss: 0.1782\n",
      "Epoch 138/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0131 - val_loss: 0.1755\n",
      "Epoch 139/1000\n",
      "36324/36324 [==============================] - 52s 1ms/step - loss: 0.0135 - val_loss: 0.1783\n",
      "Epoch 140/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0122 - val_loss: 0.1708\n",
      "Epoch 141/1000\n",
      "36324/36324 [==============================] - 51s 1ms/step - loss: 0.0132 - val_loss: 0.1701\n",
      "Epoch 142/1000\n",
      "36324/36324 [==============================] - 34s 937us/step - loss: 0.0141 - val_loss: 0.1911\n",
      "Epoch 143/1000\n",
      "36324/36324 [==============================] - 34s 946us/step - loss: 0.0145 - val_loss: 0.1759\n",
      "Epoch 144/1000\n",
      "36324/36324 [==============================] - 36s 984us/step - loss: 0.0125 - val_loss: 0.1837\n",
      "Epoch 145/1000\n",
      "36324/36324 [==============================] - 36s 992us/step - loss: 0.0129 - val_loss: 0.1767\n",
      "Epoch 146/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0115 - val_loss: 0.1898\n",
      "Epoch 147/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0113 - val_loss: 0.1794\n",
      "Epoch 148/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0113 - val_loss: 0.1852\n",
      "Epoch 149/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0113 - val_loss: 0.1832\n",
      "Epoch 150/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0117 - val_loss: 0.1819\n",
      "Epoch 151/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0123 - val_loss: 0.1791\n",
      "Epoch 152/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0109 - val_loss: 0.1711\n",
      "Epoch 153/1000\n",
      "36324/36324 [==============================] - 48s 1ms/step - loss: 0.0124 - val_loss: 0.1763\n",
      "Epoch 154/1000\n",
      "36324/36324 [==============================] - 46s 1ms/step - loss: 0.0127 - val_loss: 0.1742\n",
      "Epoch 155/1000\n",
      "36324/36324 [==============================] - 36s 997us/step - loss: 0.0119 - val_loss: 0.1752\n",
      "Epoch 156/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0115 - val_loss: 0.1847\n",
      "Epoch 157/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0122 - val_loss: 0.1776\n",
      "Epoch 158/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0136 - val_loss: 0.1812\n",
      "Epoch 159/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0130 - val_loss: 0.1680\n",
      "Epoch 160/1000\n",
      "36324/36324 [==============================] - 36s 988us/step - loss: 0.0119 - val_loss: 0.1974\n",
      "Epoch 161/1000\n",
      "36324/36324 [==============================] - 44s 1ms/step - loss: 0.0129 - val_loss: 0.1808\n",
      "Epoch 162/1000\n",
      "36324/36324 [==============================] - 93s 3ms/step - loss: 0.0134 - val_loss: 0.1874\n",
      "Epoch 163/1000\n",
      "36324/36324 [==============================] - 78s 2ms/step - loss: 0.0105 - val_loss: 0.1772\n",
      "Epoch 164/1000\n",
      "36324/36324 [==============================] - 81s 2ms/step - loss: 0.0118 - val_loss: 0.1694\n",
      "Epoch 165/1000\n",
      "36324/36324 [==============================] - 82s 2ms/step - loss: 0.0117 - val_loss: 0.1986\n",
      "Epoch 166/1000\n",
      "36324/36324 [==============================] - 87s 2ms/step - loss: 0.0177 - val_loss: 0.1880\n",
      "Epoch 167/1000\n",
      "36324/36324 [==============================] - 80s 2ms/step - loss: 0.0183 - val_loss: 0.1892\n",
      "Epoch 168/1000\n",
      "36324/36324 [==============================] - 80s 2ms/step - loss: 0.0132 - val_loss: 0.1794\n",
      "Epoch 169/1000\n",
      "36324/36324 [==============================] - 100s 3ms/step - loss: 0.0127 - val_loss: 0.1841\n",
      "Epoch 170/1000\n",
      "36324/36324 [==============================] - 82s 2ms/step - loss: 0.0118 - val_loss: 0.1888\n",
      "Epoch 171/1000\n",
      "36324/36324 [==============================] - 78s 2ms/step - loss: 0.0117 - val_loss: 0.1901\n",
      "Epoch 172/1000\n",
      "36324/36324 [==============================] - 76s 2ms/step - loss: 0.0120 - val_loss: 0.1850\n",
      "Epoch 173/1000\n",
      "36324/36324 [==============================] - 90s 2ms/step - loss: 0.0114 - val_loss: 0.1773\n",
      "Epoch 174/1000\n",
      "36324/36324 [==============================] - 80s 2ms/step - loss: 0.0114 - val_loss: 0.1753\n",
      "Epoch 175/1000\n",
      "36324/36324 [==============================] - 79s 2ms/step - loss: 0.0115 - val_loss: 0.1774\n",
      "Epoch 176/1000\n",
      "36324/36324 [==============================] - 81s 2ms/step - loss: 0.0104 - val_loss: 0.1718\n",
      "Epoch 177/1000\n",
      "36324/36324 [==============================] - 90s 2ms/step - loss: 0.0116 - val_loss: 0.1719\n",
      "Epoch 178/1000\n",
      "36324/36324 [==============================] - 79s 2ms/step - loss: 0.0117 - val_loss: 0.1648\n",
      "Epoch 179/1000\n",
      "36324/36324 [==============================] - 80s 2ms/step - loss: 0.0112 - val_loss: 0.2028\n",
      "Epoch 180/1000\n",
      "36324/36324 [==============================] - 101s 3ms/step - loss: 0.0138 - val_loss: 0.1695\n",
      "Epoch 181/1000\n",
      "36324/36324 [==============================] - 77s 2ms/step - loss: 0.0129 - val_loss: 0.1912\n",
      "Epoch 182/1000\n",
      "36324/36324 [==============================] - 77s 2ms/step - loss: 0.0116 - val_loss: 0.1685\n",
      "Epoch 183/1000\n",
      "36324/36324 [==============================] - 78s 2ms/step - loss: 0.0099 - val_loss: 0.1691\n",
      "Epoch 184/1000\n",
      "36324/36324 [==============================] - 90s 2ms/step - loss: 0.0121 - val_loss: 0.1796\n",
      "Epoch 185/1000\n",
      "36324/36324 [==============================] - 81s 2ms/step - loss: 0.0120 - val_loss: 0.1781\n",
      "Epoch 186/1000\n",
      "36324/36324 [==============================] - 82s 2ms/step - loss: 0.0107 - val_loss: 0.1830\n",
      "Epoch 187/1000\n",
      "36324/36324 [==============================] - 83s 2ms/step - loss: 0.0118 - val_loss: 0.1743\n",
      "Epoch 188/1000\n",
      "36324/36324 [==============================] - 130s 4ms/step - loss: 0.0101 - val_loss: 0.1664\n",
      "Epoch 189/1000\n",
      "36324/36324 [==============================] - 80s 2ms/step - loss: 0.0115 - val_loss: 0.1727\n",
      "Epoch 190/1000\n",
      "36324/36324 [==============================] - 79s 2ms/step - loss: 0.0117 - val_loss: 0.1743\n",
      "Epoch 191/1000\n",
      "36324/36324 [==============================] - 87s 2ms/step - loss: 0.0106 - val_loss: 0.1781\n",
      "Epoch 192/1000\n",
      "36324/36324 [==============================] - 79s 2ms/step - loss: 0.0117 - val_loss: 0.1911\n",
      "Epoch 193/1000\n",
      "36324/36324 [==============================] - 80s 2ms/step - loss: 0.0119 - val_loss: 0.1733\n",
      "Epoch 194/1000\n",
      "36324/36324 [==============================] - 88s 2ms/step - loss: 0.0123 - val_loss: 0.1745\n",
      "Epoch 195/1000\n",
      "36324/36324 [==============================] - 81s 2ms/step - loss: 0.0112 - val_loss: 0.1766\n",
      "Epoch 196/1000\n",
      "36324/36324 [==============================] - 80s 2ms/step - loss: 0.0117 - val_loss: 0.1738\n",
      "Epoch 197/1000\n",
      "36324/36324 [==============================] - 79s 2ms/step - loss: 0.0107 - val_loss: 0.1725\n",
      "Epoch 198/1000\n",
      "36324/36324 [==============================] - 107s 3ms/step - loss: 0.0110 - val_loss: 0.1822\n",
      "Epoch 199/1000\n",
      "36324/36324 [==============================] - 83s 2ms/step - loss: 0.0104 - val_loss: 0.1680\n",
      "Epoch 200/1000\n",
      "cooling down to decrease CPU tempereture\n",
      "36324/36324 [==============================] - 400s 11ms/step - loss: 0.0107 - val_loss: 0.1778\n",
      "Epoch 201/1000\n",
      "36324/36324 [==============================] - 45s 1ms/step - loss: 0.0105 - val_loss: 0.1831\n",
      "Epoch 202/1000\n",
      "36324/36324 [==============================] - 43s 1ms/step - loss: 0.0116 - val_loss: 0.1779\n",
      "Epoch 203/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0104 - val_loss: 0.1772\n",
      "Epoch 204/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0133 - val_loss: 0.1833\n",
      "Epoch 205/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0116 - val_loss: 0.1698\n",
      "Epoch 206/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0111 - val_loss: 0.1689\n",
      "Epoch 207/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0123 - val_loss: 0.1679\n",
      "Epoch 208/1000\n",
      "36324/36324 [==============================] - 46s 1ms/step - loss: 0.0112 - val_loss: 0.1770\n",
      "Epoch 209/1000\n",
      "36324/36324 [==============================] - 47s 1ms/step - loss: 0.0119 - val_loss: 0.1747\n",
      "Epoch 210/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0107 - val_loss: 0.1713\n",
      "Epoch 211/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0108 - val_loss: 0.1719\n",
      "Epoch 212/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0110 - val_loss: 0.1741\n",
      "Epoch 213/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0176 - val_loss: 0.1667\n",
      "Epoch 214/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0103 - val_loss: 0.1717\n",
      "Epoch 215/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0134 - val_loss: 0.1774\n",
      "Epoch 216/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0105 - val_loss: 0.1798\n",
      "Epoch 217/1000\n",
      "36324/36324 [==============================] - 46s 1ms/step - loss: 0.0105 - val_loss: 0.1705\n",
      "Epoch 218/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0134 - val_loss: 0.1795\n",
      "Epoch 219/1000\n",
      "36324/36324 [==============================] - 36s 986us/step - loss: 0.0108 - val_loss: 0.1674\n",
      "Epoch 220/1000\n",
      "36324/36324 [==============================] - 35s 956us/step - loss: 0.0108 - val_loss: 0.1729\n",
      "Epoch 221/1000\n",
      "36324/36324 [==============================] - 34s 940us/step - loss: 0.0125 - val_loss: 0.1623\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36324/36324 [==============================] - 34s 949us/step - loss: 0.0108 - val_loss: 0.1752\n",
      "Epoch 223/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0127 - val_loss: 0.1672\n",
      "Epoch 224/1000\n",
      "36324/36324 [==============================] - 43s 1ms/step - loss: 0.0134 - val_loss: 0.1784\n",
      "Epoch 225/1000\n",
      "36324/36324 [==============================] - 46s 1ms/step - loss: 0.0115 - val_loss: 0.1843\n",
      "Epoch 226/1000\n",
      "36324/36324 [==============================] - 34s 927us/step - loss: 0.0112 - val_loss: 0.1718\n",
      "Epoch 227/1000\n",
      "36324/36324 [==============================] - 36s 995us/step - loss: 0.0097 - val_loss: 0.1785\n",
      "Epoch 228/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0122 - val_loss: 0.1684\n",
      "Epoch 229/1000\n",
      "36324/36324 [==============================] - 36s 1ms/step - loss: 0.0101 - val_loss: 0.1724\n",
      "Epoch 230/1000\n",
      "36324/36324 [==============================] - 36s 999us/step - loss: 0.0102 - val_loss: 0.1805\n",
      "Epoch 231/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0107 - val_loss: 0.1840\n",
      "Epoch 232/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0107 - val_loss: 0.1692\n",
      "Epoch 233/1000\n",
      "36324/36324 [==============================] - 44s 1ms/step - loss: 0.0094 - val_loss: 0.1701\n",
      "Epoch 234/1000\n",
      "36324/36324 [==============================] - 34s 944us/step - loss: 0.0112 - val_loss: 0.1776\n",
      "Epoch 235/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0101 - val_loss: 0.1662\n",
      "Epoch 236/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0102 - val_loss: 0.1737\n",
      "Epoch 237/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0110 - val_loss: 0.1808\n",
      "Epoch 238/1000\n",
      "36324/36324 [==============================] - 35s 967us/step - loss: 0.0103 - val_loss: 0.1704\n",
      "Epoch 239/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0104 - val_loss: 0.1638\n",
      "Epoch 240/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0108 - val_loss: 0.1722\n",
      "Epoch 241/1000\n",
      "36324/36324 [==============================] - 44s 1ms/step - loss: 0.0112 - val_loss: 0.1725\n",
      "Epoch 242/1000\n",
      "36324/36324 [==============================] - 32s 893us/step - loss: 0.0103 - val_loss: 0.1818\n",
      "Epoch 243/1000\n",
      "36324/36324 [==============================] - 35s 962us/step - loss: 0.0109 - val_loss: 0.1890\n",
      "Epoch 244/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0119 - val_loss: 0.1764\n",
      "Epoch 245/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0115 - val_loss: 0.1739\n",
      "Epoch 246/1000\n",
      "36324/36324 [==============================] - 36s 991us/step - loss: 0.0107 - val_loss: 0.1720\n",
      "Epoch 247/1000\n",
      "36324/36324 [==============================] - 34s 949us/step - loss: 0.0104 - val_loss: 0.1757\n",
      "Epoch 248/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0121 - val_loss: 0.1795\n",
      "Epoch 249/1000\n",
      "36324/36324 [==============================] - 60s 2ms/step - loss: 0.0105 - val_loss: 0.1809\n",
      "Epoch 250/1000\n",
      "36324/36324 [==============================] - 43s 1ms/step - loss: 0.0099 - val_loss: 0.1686\n",
      "Epoch 251/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0098 - val_loss: 0.1672\n",
      "Epoch 252/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0115 - val_loss: 0.1980\n",
      "Epoch 253/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0122 - val_loss: 0.1781\n",
      "Epoch 254/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0107 - val_loss: 0.1773\n",
      "Epoch 255/1000\n",
      "36324/36324 [==============================] - 35s 962us/step - loss: 0.0123 - val_loss: 0.1694\n",
      "Epoch 256/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0105 - val_loss: 0.1682\n",
      "Epoch 257/1000\n",
      "36324/36324 [==============================] - 36s 999us/step - loss: 0.0105 - val_loss: 0.1781\n",
      "Epoch 258/1000\n",
      "36324/36324 [==============================] - 36s 1ms/step - loss: 0.0110 - val_loss: 0.1762\n",
      "Epoch 259/1000\n",
      "36324/36324 [==============================] - 36s 984us/step - loss: 0.0095 - val_loss: 0.1789\n",
      "Epoch 260/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0155 - val_loss: 0.1756\n",
      "Epoch 261/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0117 - val_loss: 0.1791\n",
      "Epoch 262/1000\n",
      "36324/36324 [==============================] - 36s 989us/step - loss: 0.0104 - val_loss: 0.1795\n",
      "Epoch 263/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0115 - val_loss: 0.1758\n",
      "Epoch 264/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0103 - val_loss: 0.1712\n",
      "Epoch 265/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0104 - val_loss: 0.1867\n",
      "Epoch 266/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0110 - val_loss: 0.1682\n",
      "Epoch 267/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0096 - val_loss: 0.1915\n",
      "Epoch 268/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0090 - val_loss: 0.1820\n",
      "Epoch 269/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0100 - val_loss: 0.1688\n",
      "Epoch 270/1000\n",
      "36324/36324 [==============================] - 33s 901us/step - loss: 0.0104 - val_loss: 0.1794\n",
      "Epoch 271/1000\n",
      "36324/36324 [==============================] - 33s 908us/step - loss: 0.0105 - val_loss: 0.1786\n",
      "Epoch 272/1000\n",
      "36324/36324 [==============================] - 35s 973us/step - loss: 0.0101 - val_loss: 0.1711\n",
      "Epoch 273/1000\n",
      "36324/36324 [==============================] - 44s 1ms/step - loss: 0.0102 - val_loss: 0.1840\n",
      "Epoch 274/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0110 - val_loss: 0.1853\n",
      "Epoch 275/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0108 - val_loss: 0.1848\n",
      "Epoch 276/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0123 - val_loss: 0.1684\n",
      "Epoch 277/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0117 - val_loss: 0.1629\n",
      "Epoch 278/1000\n",
      "36324/36324 [==============================] - 36s 993us/step - loss: 0.0130 - val_loss: 0.1654\n",
      "Epoch 279/1000\n",
      "36324/36324 [==============================] - 45s 1ms/step - loss: 0.0102 - val_loss: 0.1712\n",
      "Epoch 280/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0115 - val_loss: 0.1696\n",
      "Epoch 281/1000\n",
      "36324/36324 [==============================] - 43s 1ms/step - loss: 0.0103 - val_loss: 0.1787\n",
      "Epoch 282/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0116 - val_loss: 0.1765\n",
      "Epoch 283/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0123 - val_loss: 0.1770\n",
      "Epoch 284/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0103 - val_loss: 0.1806\n",
      "Epoch 285/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0092 - val_loss: 0.1777\n",
      "Epoch 286/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0088 - val_loss: 0.1811\n",
      "Epoch 287/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0105 - val_loss: 0.1790\n",
      "Epoch 288/1000\n",
      "36324/36324 [==============================] - 57s 2ms/step - loss: 0.0095 - val_loss: 0.1619\n",
      "Epoch 289/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0091 - val_loss: 0.1751\n",
      "Epoch 290/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0107 - val_loss: 0.1748\n",
      "Epoch 291/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0094 - val_loss: 0.1794\n",
      "Epoch 292/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0104 - val_loss: 0.1686\n",
      "Epoch 293/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0098 - val_loss: 0.1726\n",
      "Epoch 294/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0092 - val_loss: 0.1788\n",
      "Epoch 295/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0109 - val_loss: 0.1662\n",
      "Epoch 296/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0112 - val_loss: 0.1746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0118 - val_loss: 0.1948\n",
      "Epoch 298/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0121 - val_loss: 0.1727\n",
      "Epoch 299/1000\n",
      "36324/36324 [==============================] - 36s 996us/step - loss: 0.0095 - val_loss: 0.1813\n",
      "Epoch 300/1000\n",
      "cooling down to decrease CPU tempereture\n",
      "36324/36324 [==============================] - 378s 10ms/step - loss: 0.0106 - val_loss: 0.1737\n",
      "Epoch 301/1000\n",
      "36324/36324 [==============================] - 43s 1ms/step - loss: 0.0116 - val_loss: 0.1750\n",
      "Epoch 302/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0102 - val_loss: 0.1726\n",
      "Epoch 303/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0093 - val_loss: 0.1755\n",
      "Epoch 304/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0104 - val_loss: 0.1777\n",
      "Epoch 305/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0104 - val_loss: 0.1762\n",
      "Epoch 306/1000\n",
      "36324/36324 [==============================] - 34s 933us/step - loss: 0.0106 - val_loss: 0.1838\n",
      "Epoch 307/1000\n",
      "36324/36324 [==============================] - 36s 996us/step - loss: 0.0116 - val_loss: 0.1642\n",
      "Epoch 308/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0117 - val_loss: 0.1757\n",
      "Epoch 309/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0114 - val_loss: 0.1719\n",
      "Epoch 310/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0095 - val_loss: 0.1759\n",
      "Epoch 311/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0091 - val_loss: 0.1716\n",
      "Epoch 312/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0093 - val_loss: 0.1833\n",
      "Epoch 313/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0093 - val_loss: 0.1719\n",
      "Epoch 314/1000\n",
      "36324/36324 [==============================] - 36s 980us/step - loss: 0.0104 - val_loss: 0.1715\n",
      "Epoch 315/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0122 - val_loss: 0.1779\n",
      "Epoch 316/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0096 - val_loss: 0.1732\n",
      "Epoch 317/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0101 - val_loss: 0.1715\n",
      "Epoch 318/1000\n",
      "36324/36324 [==============================] - 43s 1ms/step - loss: 0.0111 - val_loss: 0.1762\n",
      "Epoch 319/1000\n",
      "36324/36324 [==============================] - 44s 1ms/step - loss: 0.0102 - val_loss: 0.1748\n",
      "Epoch 320/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0093 - val_loss: 0.1694\n",
      "Epoch 321/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0096 - val_loss: 0.1678\n",
      "Epoch 322/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0088 - val_loss: 0.1762\n",
      "Epoch 323/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0090 - val_loss: 0.1775\n",
      "Epoch 324/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0101 - val_loss: 0.1788\n",
      "Epoch 325/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0102 - val_loss: 0.1861\n",
      "Epoch 326/1000\n",
      "36324/36324 [==============================] - 56s 2ms/step - loss: 0.0100 - val_loss: 0.1837\n",
      "Epoch 327/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0099 - val_loss: 0.1776\n",
      "Epoch 328/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0105 - val_loss: 0.1691\n",
      "Epoch 329/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0100 - val_loss: 0.1973\n",
      "Epoch 330/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0098 - val_loss: 0.1728\n",
      "Epoch 331/1000\n",
      "36324/36324 [==============================] - 36s 1000us/step - loss: 0.0093 - val_loss: 0.1772\n",
      "Epoch 332/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0098 - val_loss: 0.1836\n",
      "Epoch 333/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0102 - val_loss: 0.1699\n",
      "Epoch 334/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0097 - val_loss: 0.1884\n",
      "Epoch 335/1000\n",
      "36324/36324 [==============================] - 34s 948us/step - loss: 0.0094 - val_loss: 0.1709\n",
      "Epoch 336/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0097 - val_loss: 0.1662\n",
      "Epoch 337/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0102 - val_loss: 0.1688\n",
      "Epoch 338/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0102 - val_loss: 0.1669\n",
      "Epoch 339/1000\n",
      "36324/36324 [==============================] - 35s 952us/step - loss: 0.0105 - val_loss: 0.1723\n",
      "Epoch 340/1000\n",
      "36324/36324 [==============================] - 34s 942us/step - loss: 0.0097 - val_loss: 0.1750\n",
      "Epoch 341/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0111 - val_loss: 0.1727\n",
      "Epoch 342/1000\n",
      "36324/36324 [==============================] - 43s 1ms/step - loss: 0.0097 - val_loss: 0.1730\n",
      "Epoch 343/1000\n",
      "36324/36324 [==============================] - 35s 972us/step - loss: 0.0090 - val_loss: 0.1762\n",
      "Epoch 344/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0100 - val_loss: 0.1704\n",
      "Epoch 345/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0098 - val_loss: 0.1752\n",
      "Epoch 346/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0121 - val_loss: 0.1678\n",
      "Epoch 347/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0105 - val_loss: 0.1867\n",
      "Epoch 348/1000\n",
      "36324/36324 [==============================] - 35s 973us/step - loss: 0.0090 - val_loss: 0.1764\n",
      "Epoch 349/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0094 - val_loss: 0.1746\n",
      "Epoch 350/1000\n",
      "36324/36324 [==============================] - 45s 1ms/step - loss: 0.0097 - val_loss: 0.1844\n",
      "Epoch 351/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0099 - val_loss: 0.1776\n",
      "Epoch 352/1000\n",
      "36324/36324 [==============================] - 35s 962us/step - loss: 0.0101 - val_loss: 0.1779\n",
      "Epoch 353/1000\n",
      "36324/36324 [==============================] - 35s 964us/step - loss: 0.0104 - val_loss: 0.1891\n",
      "Epoch 354/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0103 - val_loss: 0.1805\n",
      "Epoch 355/1000\n",
      "36324/36324 [==============================] - 43s 1ms/step - loss: 0.0096 - val_loss: 0.1724\n",
      "Epoch 356/1000\n",
      "36324/36324 [==============================] - 35s 958us/step - loss: 0.0095 - val_loss: 0.1668\n",
      "Epoch 357/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0096 - val_loss: 0.1794\n",
      "Epoch 358/1000\n",
      "36324/36324 [==============================] - 45s 1ms/step - loss: 0.0087 - val_loss: 0.1786\n",
      "Epoch 359/1000\n",
      "36324/36324 [==============================] - 33s 920us/step - loss: 0.0111 - val_loss: 0.1751\n",
      "Epoch 360/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0104 - val_loss: 0.1935\n",
      "Epoch 361/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0099 - val_loss: 0.1653\n",
      "Epoch 362/1000\n",
      "36324/36324 [==============================] - 33s 899us/step - loss: 0.0102 - val_loss: 0.1748\n",
      "Epoch 363/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0105 - val_loss: 0.2003\n",
      "Epoch 364/1000\n",
      "36324/36324 [==============================] - 52s 1ms/step - loss: 0.0114 - val_loss: 0.1871\n",
      "Epoch 365/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0099 - val_loss: 0.1747\n",
      "Epoch 366/1000\n",
      "36324/36324 [==============================] - 50s 1ms/step - loss: 0.0092 - val_loss: 0.1712\n",
      "Epoch 367/1000\n",
      "36324/36324 [==============================] - 62s 2ms/step - loss: 0.0100 - val_loss: 0.1840\n",
      "Epoch 368/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0092 - val_loss: 0.1716\n",
      "Epoch 369/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0098 - val_loss: 0.1750\n",
      "Epoch 370/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0098 - val_loss: 0.1702\n",
      "Epoch 371/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0109 - val_loss: 0.1714\n",
      "Epoch 372/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0101 - val_loss: 0.1761\n",
      "Epoch 373/1000\n",
      "36324/36324 [==============================] - 48s 1ms/step - loss: 0.0092 - val_loss: 0.1880\n",
      "Epoch 374/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0100 - val_loss: 0.1746\n",
      "Epoch 375/1000\n",
      "36324/36324 [==============================] - 35s 967us/step - loss: 0.0089 - val_loss: 0.1799\n",
      "Epoch 376/1000\n",
      "36324/36324 [==============================] - 34s 935us/step - loss: 0.0090 - val_loss: 0.1806\n",
      "Epoch 377/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0090 - val_loss: 0.1785\n",
      "Epoch 378/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0187 - val_loss: 0.1872\n",
      "Epoch 379/1000\n",
      "36324/36324 [==============================] - 35s 968us/step - loss: 0.0120 - val_loss: 0.1804\n",
      "Epoch 380/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0108 - val_loss: 0.1738\n",
      "Epoch 381/1000\n",
      "36324/36324 [==============================] - 45s 1ms/step - loss: 0.0122 - val_loss: 0.2148\n",
      "Epoch 382/1000\n",
      "36324/36324 [==============================] - 36s 989us/step - loss: 0.0107 - val_loss: 0.1712\n",
      "Epoch 383/1000\n",
      "36324/36324 [==============================] - 35s 975us/step - loss: 0.0098 - val_loss: 0.1682\n",
      "Epoch 384/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0110 - val_loss: 0.1829\n",
      "Epoch 385/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0108 - val_loss: 0.1731\n",
      "Epoch 386/1000\n",
      "36324/36324 [==============================] - 36s 1ms/step - loss: 0.0108 - val_loss: 0.1754\n",
      "Epoch 387/1000\n",
      "36324/36324 [==============================] - 36s 992us/step - loss: 0.0092 - val_loss: 0.1722\n",
      "Epoch 388/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0086 - val_loss: 0.1719\n",
      "Epoch 389/1000\n",
      "36324/36324 [==============================] - 43s 1ms/step - loss: 0.0086 - val_loss: 0.1829\n",
      "Epoch 390/1000\n",
      "36324/36324 [==============================] - 36s 999us/step - loss: 0.0109 - val_loss: 0.1666\n",
      "Epoch 391/1000\n",
      "36324/36324 [==============================] - 69s 2ms/step - loss: 0.0103 - val_loss: 0.1710\n",
      "Epoch 392/1000\n",
      "36324/36324 [==============================] - 79s 2ms/step - loss: 0.0101 - val_loss: 0.1759\n",
      "Epoch 393/1000\n",
      "36324/36324 [==============================] - 81s 2ms/step - loss: 0.0096 - val_loss: 0.1649\n",
      "Epoch 394/1000\n",
      "36324/36324 [==============================] - 95s 3ms/step - loss: 0.0099 - val_loss: 0.1710\n",
      "Epoch 395/1000\n",
      "36324/36324 [==============================] - 77s 2ms/step - loss: 0.0109 - val_loss: 0.1620\n",
      "Epoch 396/1000\n",
      "36324/36324 [==============================] - 79s 2ms/step - loss: 0.0094 - val_loss: 0.1741\n",
      "Epoch 397/1000\n",
      "36324/36324 [==============================] - 79s 2ms/step - loss: 0.0105 - val_loss: 0.1778\n",
      "Epoch 398/1000\n",
      "36324/36324 [==============================] - 151s 4ms/step - loss: 0.0098 - val_loss: 0.1810\n",
      "Epoch 399/1000\n",
      "36324/36324 [==============================] - 78s 2ms/step - loss: 0.0090 - val_loss: 0.1799\n",
      "Epoch 400/1000\n",
      "cooling down to decrease CPU tempereture\n",
      "36324/36324 [==============================] - 398s 11ms/step - loss: 0.0101 - val_loss: 0.1697\n",
      "Epoch 401/1000\n",
      "36324/36324 [==============================] - 66s 2ms/step - loss: 0.0111 - val_loss: 0.1722\n",
      "Epoch 402/1000\n",
      "36324/36324 [==============================] - 63s 2ms/step - loss: 0.0104 - val_loss: 0.1775\n",
      "Epoch 403/1000\n",
      "36324/36324 [==============================] - 76s 2ms/step - loss: 0.0092 - val_loss: 0.1774\n",
      "Epoch 404/1000\n",
      "36324/36324 [==============================] - 77s 2ms/step - loss: 0.0112 - val_loss: 0.1704\n",
      "Epoch 405/1000\n",
      "36324/36324 [==============================] - 83s 2ms/step - loss: 0.0092 - val_loss: 0.1675\n",
      "Epoch 406/1000\n",
      "36324/36324 [==============================] - 75s 2ms/step - loss: 0.0089 - val_loss: 0.1717\n",
      "Epoch 407/1000\n",
      "36324/36324 [==============================] - 76s 2ms/step - loss: 0.0091 - val_loss: 0.1754\n",
      "Epoch 408/1000\n",
      "36324/36324 [==============================] - 79s 2ms/step - loss: 0.0098 - val_loss: 0.1650\n",
      "Epoch 409/1000\n",
      "36324/36324 [==============================] - 78s 2ms/step - loss: 0.0105 - val_loss: 0.1718\n",
      "Epoch 410/1000\n",
      "36324/36324 [==============================] - 77s 2ms/step - loss: 0.0105 - val_loss: 0.1765\n",
      "Epoch 411/1000\n",
      "36324/36324 [==============================] - 81s 2ms/step - loss: 0.0105 - val_loss: 0.1805\n",
      "Epoch 412/1000\n",
      "36324/36324 [==============================] - 102s 3ms/step - loss: 0.0098 - val_loss: 0.1799\n",
      "Epoch 413/1000\n",
      "36324/36324 [==============================] - 83s 2ms/step - loss: 0.0087 - val_loss: 0.1725\n",
      "Epoch 414/1000\n",
      "36324/36324 [==============================] - 78s 2ms/step - loss: 0.0086 - val_loss: 0.1668\n",
      "Epoch 415/1000\n",
      "36324/36324 [==============================] - 79s 2ms/step - loss: 0.0093 - val_loss: 0.1616\n",
      "Epoch 416/1000\n",
      "36324/36324 [==============================] - 89s 2ms/step - loss: 0.0088 - val_loss: 0.1860\n",
      "Epoch 417/1000\n",
      "36324/36324 [==============================] - 59s 2ms/step - loss: 0.0119 - val_loss: 0.1681\n",
      "Epoch 418/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0100 - val_loss: 0.1694\n",
      "Epoch 419/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0091 - val_loss: 0.1649\n",
      "Epoch 420/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0087 - val_loss: 0.1677\n",
      "Epoch 421/1000\n",
      "36324/36324 [==============================] - 49s 1ms/step - loss: 0.0087 - val_loss: 0.1770\n",
      "Epoch 422/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0090 - val_loss: 0.1668\n",
      "Epoch 423/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0096 - val_loss: 0.1715\n",
      "Epoch 424/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0093 - val_loss: 0.1729\n",
      "Epoch 425/1000\n",
      "36324/36324 [==============================] - 36s 996us/step - loss: 0.0099 - val_loss: 0.1681\n",
      "Epoch 426/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0106 - val_loss: 0.1730\n",
      "Epoch 427/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0091 - val_loss: 0.1756\n",
      "Epoch 428/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0098 - val_loss: 0.1657\n",
      "Epoch 429/1000\n",
      "36324/36324 [==============================] - 46s 1ms/step - loss: 0.0101 - val_loss: 0.1703\n",
      "Epoch 430/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0096 - val_loss: 0.1750\n",
      "Epoch 431/1000\n",
      "36324/36324 [==============================] - 34s 942us/step - loss: 0.0099 - val_loss: 0.1614\n",
      "Epoch 432/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0098 - val_loss: 0.1761\n",
      "Epoch 433/1000\n",
      "36324/36324 [==============================] - 45s 1ms/step - loss: 0.0092 - val_loss: 0.1670\n",
      "Epoch 434/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0097 - val_loss: 0.1738\n",
      "Epoch 435/1000\n",
      "36324/36324 [==============================] - 34s 936us/step - loss: 0.0098 - val_loss: 0.1745\n",
      "Epoch 436/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0099 - val_loss: 0.1634\n",
      "Epoch 437/1000\n",
      "36324/36324 [==============================] - 43s 1ms/step - loss: 0.0101 - val_loss: 0.1855\n",
      "Epoch 438/1000\n",
      "36324/36324 [==============================] - 34s 949us/step - loss: 0.0102 - val_loss: 0.1790\n",
      "Epoch 439/1000\n",
      "36324/36324 [==============================] - 36s 1ms/step - loss: 0.0100 - val_loss: 0.1705\n",
      "Epoch 440/1000\n",
      "36324/36324 [==============================] - 36s 1ms/step - loss: 0.0098 - val_loss: 0.1731\n",
      "Epoch 441/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0087 - val_loss: 0.1683\n",
      "Epoch 442/1000\n",
      "36324/36324 [==============================] - 36s 1ms/step - loss: 0.0098 - val_loss: 0.1672\n",
      "Epoch 443/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0111 - val_loss: 0.1699\n",
      "Epoch 444/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0089 - val_loss: 0.1773\n",
      "Epoch 445/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36324/36324 [==============================] - 50s 1ms/step - loss: 0.0085 - val_loss: 0.1634\n",
      "Epoch 446/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0093 - val_loss: 0.1700\n",
      "Epoch 447/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0083 - val_loss: 0.1736\n",
      "Epoch 448/1000\n",
      "36324/36324 [==============================] - 56s 2ms/step - loss: 0.0100 - val_loss: 0.1675\n",
      "Epoch 449/1000\n",
      "36324/36324 [==============================] - 35s 977us/step - loss: 0.0100 - val_loss: 0.1772\n",
      "Epoch 450/1000\n",
      "36324/36324 [==============================] - 34s 946us/step - loss: 0.0090 - val_loss: 0.1711\n",
      "Epoch 451/1000\n",
      "36324/36324 [==============================] - 34s 946us/step - loss: 0.0085 - val_loss: 0.1818\n",
      "Epoch 452/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0089 - val_loss: 0.1629\n",
      "Epoch 453/1000\n",
      "36324/36324 [==============================] - 43s 1ms/step - loss: 0.0096 - val_loss: 0.1751\n",
      "Epoch 454/1000\n",
      "36324/36324 [==============================] - 35s 976us/step - loss: 0.0095 - val_loss: 0.1647\n",
      "Epoch 455/1000\n",
      "36324/36324 [==============================] - 33s 920us/step - loss: 0.0092 - val_loss: 0.1656\n",
      "Epoch 456/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0083 - val_loss: 0.1764\n",
      "Epoch 457/1000\n",
      "36324/36324 [==============================] - 34s 922us/step - loss: 0.0100 - val_loss: 0.1720\n",
      "Epoch 458/1000\n",
      "36324/36324 [==============================] - 33s 914us/step - loss: 0.0100 - val_loss: 0.1718\n",
      "Epoch 459/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0104 - val_loss: 0.1635\n",
      "Epoch 460/1000\n",
      "36324/36324 [==============================] - 36s 990us/step - loss: 0.0116 - val_loss: 0.1686\n",
      "Epoch 461/1000\n",
      "36324/36324 [==============================] - 67s 2ms/step - loss: 0.0103 - val_loss: 0.1721\n",
      "Epoch 462/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0107 - val_loss: 0.1704\n",
      "Epoch 463/1000\n",
      "36324/36324 [==============================] - 35s 950us/step - loss: 0.0094 - val_loss: 0.1677\n",
      "Epoch 464/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0104 - val_loss: 0.1647\n",
      "Epoch 465/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0097 - val_loss: 0.1687\n",
      "Epoch 466/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0089 - val_loss: 0.1752\n",
      "Epoch 467/1000\n",
      "36324/36324 [==============================] - 44s 1ms/step - loss: 0.0105 - val_loss: 0.1621\n",
      "Epoch 468/1000\n",
      "36324/36324 [==============================] - 47s 1ms/step - loss: 0.0096 - val_loss: 0.1678\n",
      "Epoch 469/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0091 - val_loss: 0.1767\n",
      "Epoch 470/1000\n",
      "36324/36324 [==============================] - 36s 995us/step - loss: 0.0086 - val_loss: 0.1698\n",
      "Epoch 471/1000\n",
      "36324/36324 [==============================] - 32s 894us/step - loss: 0.0084 - val_loss: 0.1789\n",
      "Epoch 472/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0094 - val_loss: 0.1766\n",
      "Epoch 473/1000\n",
      "36324/36324 [==============================] - 36s 987us/step - loss: 0.0088 - val_loss: 0.1714\n",
      "Epoch 474/1000\n",
      "36324/36324 [==============================] - 33s 916us/step - loss: 0.0096 - val_loss: 0.1719\n",
      "Epoch 475/1000\n",
      "36324/36324 [==============================] - 36s 1ms/step - loss: 0.0112 - val_loss: 0.1789\n",
      "Epoch 476/1000\n",
      "36324/36324 [==============================] - 49s 1ms/step - loss: 0.0093 - val_loss: 0.1721\n",
      "Epoch 477/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0089 - val_loss: 0.1650\n",
      "Epoch 478/1000\n",
      "36324/36324 [==============================] - 36s 993us/step - loss: 0.0094 - val_loss: 0.1753\n",
      "Epoch 479/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0101 - val_loss: 0.1749\n",
      "Epoch 480/1000\n",
      "36324/36324 [==============================] - 36s 991us/step - loss: 0.0092 - val_loss: 0.1607\n",
      "Epoch 481/1000\n",
      "36324/36324 [==============================] - 36s 993us/step - loss: 0.0088 - val_loss: 0.1652\n",
      "Epoch 482/1000\n",
      "36324/36324 [==============================] - 33s 909us/step - loss: 0.0090 - val_loss: 0.1654\n",
      "Epoch 483/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0095 - val_loss: 0.1670\n",
      "Epoch 484/1000\n",
      "36324/36324 [==============================] - 45s 1ms/step - loss: 0.0084 - val_loss: 0.1731\n",
      "Epoch 485/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0084 - val_loss: 0.1765\n",
      "Epoch 486/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0088 - val_loss: 0.1621\n",
      "Epoch 487/1000\n",
      "36324/36324 [==============================] - 35s 951us/step - loss: 0.0091 - val_loss: 0.1715\n",
      "Epoch 488/1000\n",
      "36324/36324 [==============================] - 32s 881us/step - loss: 0.0093 - val_loss: 0.1552\n",
      "Epoch 489/1000\n",
      "36324/36324 [==============================] - 35s 965us/step - loss: 0.0095 - val_loss: 0.1652\n",
      "Epoch 490/1000\n",
      "36324/36324 [==============================] - 34s 946us/step - loss: 0.0105 - val_loss: 0.1697\n",
      "Epoch 491/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0103 - val_loss: 0.1957\n",
      "Epoch 492/1000\n",
      "36324/36324 [==============================] - 46s 1ms/step - loss: 0.0104 - val_loss: 0.1713\n",
      "Epoch 493/1000\n",
      "36324/36324 [==============================] - 78s 2ms/step - loss: 0.0091 - val_loss: 0.1757\n",
      "Epoch 494/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0086 - val_loss: 0.1702\n",
      "Epoch 495/1000\n",
      "36324/36324 [==============================] - 52s 1ms/step - loss: 0.0100 - val_loss: 0.1681\n",
      "Epoch 496/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0102 - val_loss: 0.1771\n",
      "Epoch 497/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0095 - val_loss: 0.1682\n",
      "Epoch 498/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0094 - val_loss: 0.1832\n",
      "Epoch 499/1000\n",
      "36324/36324 [==============================] - 67s 2ms/step - loss: 0.0110 - val_loss: 0.1801\n",
      "Epoch 500/1000\n",
      "cooling down to decrease CPU tempereture\n",
      "36324/36324 [==============================] - 418s 12ms/step - loss: 0.0099 - val_loss: 0.1818\n",
      "Epoch 501/1000\n",
      "36324/36324 [==============================] - 82s 2ms/step - loss: 0.0097 - val_loss: 0.1690\n",
      "Epoch 502/1000\n",
      "36324/36324 [==============================] - 86s 2ms/step - loss: 0.0093 - val_loss: 0.1734\n",
      "Epoch 503/1000\n",
      "36324/36324 [==============================] - 98s 3ms/step - loss: 0.0096 - val_loss: 0.1752\n",
      "Epoch 504/1000\n",
      "36324/36324 [==============================] - 79s 2ms/step - loss: 0.0086 - val_loss: 0.1759\n",
      "Epoch 505/1000\n",
      "36324/36324 [==============================] - 76s 2ms/step - loss: 0.0090 - val_loss: 0.1817\n",
      "Epoch 506/1000\n",
      "36324/36324 [==============================] - 135s 4ms/step - loss: 0.0087 - val_loss: 0.1753\n",
      "Epoch 507/1000\n",
      "36324/36324 [==============================] - 77s 2ms/step - loss: 0.0084 - val_loss: 0.1731\n",
      "Epoch 508/1000\n",
      "36324/36324 [==============================] - 80s 2ms/step - loss: 0.0085 - val_loss: 0.1786\n",
      "Epoch 509/1000\n",
      "36324/36324 [==============================] - 110s 3ms/step - loss: 0.0092 - val_loss: 0.1688\n",
      "Epoch 510/1000\n",
      "36324/36324 [==============================] - 89s 2ms/step - loss: 0.0094 - val_loss: 0.1857\n",
      "Epoch 511/1000\n",
      "36324/36324 [==============================] - 79s 2ms/step - loss: 0.0092 - val_loss: 0.1731\n",
      "Epoch 512/1000\n",
      "36324/36324 [==============================] - 83s 2ms/step - loss: 0.0085 - val_loss: 0.1725\n",
      "Epoch 513/1000\n",
      "36324/36324 [==============================] - 85s 2ms/step - loss: 0.0091 - val_loss: 0.1740\n",
      "Epoch 514/1000\n",
      "36324/36324 [==============================] - 75s 2ms/step - loss: 0.0087 - val_loss: 0.1688\n",
      "Epoch 515/1000\n",
      "36324/36324 [==============================] - 78s 2ms/step - loss: 0.0086 - val_loss: 0.1702\n",
      "Epoch 516/1000\n",
      "36324/36324 [==============================] - 99s 3ms/step - loss: 0.0090 - val_loss: 0.1668\n",
      "Epoch 517/1000\n",
      "36324/36324 [==============================] - 90s 2ms/step - loss: 0.0089 - val_loss: 0.1778\n",
      "Epoch 518/1000\n",
      "36324/36324 [==============================] - 69s 2ms/step - loss: 0.0096 - val_loss: 0.1627\n",
      "Epoch 519/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0097 - val_loss: 0.1752\n",
      "Epoch 520/1000\n",
      "36324/36324 [==============================] - 43s 1ms/step - loss: 0.0095 - val_loss: 0.1721\n",
      "Epoch 521/1000\n",
      "36324/36324 [==============================] - 45s 1ms/step - loss: 0.0084 - val_loss: 0.1620\n",
      "Epoch 522/1000\n",
      "36324/36324 [==============================] - 75s 2ms/step - loss: 0.0095 - val_loss: 0.1691\n",
      "Epoch 523/1000\n",
      "36324/36324 [==============================] - 81s 2ms/step - loss: 0.0116 - val_loss: 0.1691\n",
      "Epoch 524/1000\n",
      "36324/36324 [==============================] - 78s 2ms/step - loss: 0.0097 - val_loss: 0.1731\n",
      "Epoch 525/1000\n",
      "36324/36324 [==============================] - 83s 2ms/step - loss: 0.0112 - val_loss: 0.1834\n",
      "Epoch 526/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0084 - val_loss: 0.1760\n",
      "Epoch 527/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0088 - val_loss: 0.1769\n",
      "Epoch 528/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0093 - val_loss: 0.1789\n",
      "Epoch 529/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0095 - val_loss: 0.1794\n",
      "Epoch 530/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0102 - val_loss: 0.1820\n",
      "Epoch 531/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0079 - val_loss: 0.1722\n",
      "Epoch 532/1000\n",
      "36324/36324 [==============================] - 46s 1ms/step - loss: 0.0082 - val_loss: 0.1887\n",
      "Epoch 533/1000\n",
      "36324/36324 [==============================] - 33s 913us/step - loss: 0.0092 - val_loss: 0.1801\n",
      "Epoch 534/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0086 - val_loss: 0.1766\n",
      "Epoch 535/1000\n",
      "36324/36324 [==============================] - 35s 955us/step - loss: 0.0082 - val_loss: 0.1781\n",
      "Epoch 536/1000\n",
      "36324/36324 [==============================] - 36s 1ms/step - loss: 0.0094 - val_loss: 0.1693\n",
      "Epoch 537/1000\n",
      "36324/36324 [==============================] - 33s 914us/step - loss: 0.0098 - val_loss: 0.1756\n",
      "Epoch 538/1000\n",
      "36324/36324 [==============================] - 36s 991us/step - loss: 0.0087 - val_loss: 0.1708\n",
      "Epoch 539/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0093 - val_loss: 0.1735\n",
      "Epoch 540/1000\n",
      "36324/36324 [==============================] - 54s 1ms/step - loss: 0.0090 - val_loss: 0.1742\n",
      "Epoch 541/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0090 - val_loss: 0.1699\n",
      "Epoch 542/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0087 - val_loss: 0.1689\n",
      "Epoch 543/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0083 - val_loss: 0.1740\n",
      "Epoch 544/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0103 - val_loss: 0.1777\n",
      "Epoch 545/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0082 - val_loss: 0.1644\n",
      "Epoch 546/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0106 - val_loss: 0.1716\n",
      "Epoch 547/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0107 - val_loss: 0.1718\n",
      "Epoch 548/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0085 - val_loss: 0.1745\n",
      "Epoch 549/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0089 - val_loss: 0.1695\n",
      "Epoch 550/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0081 - val_loss: 0.1611\n",
      "Epoch 551/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0081 - val_loss: 0.1691\n",
      "Epoch 552/1000\n",
      "36324/36324 [==============================] - 34s 947us/step - loss: 0.0090 - val_loss: 0.1862\n",
      "Epoch 553/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0098 - val_loss: 0.1815\n",
      "Epoch 554/1000\n",
      "36324/36324 [==============================] - 35s 975us/step - loss: 0.0090 - val_loss: 0.1698\n",
      "Epoch 555/1000\n",
      "36324/36324 [==============================] - 36s 992us/step - loss: 0.0082 - val_loss: 0.1759\n",
      "Epoch 556/1000\n",
      "36324/36324 [==============================] - 43s 1ms/step - loss: 0.0080 - val_loss: 0.1759\n",
      "Epoch 557/1000\n",
      "36324/36324 [==============================] - 36s 993us/step - loss: 0.0103 - val_loss: 0.1778\n",
      "Epoch 558/1000\n",
      "36324/36324 [==============================] - 34s 938us/step - loss: 0.0099 - val_loss: 0.1808\n",
      "Epoch 559/1000\n",
      "36324/36324 [==============================] - 35s 970us/step - loss: 0.0094 - val_loss: 0.1696\n",
      "Epoch 560/1000\n",
      "36324/36324 [==============================] - 33s 921us/step - loss: 0.0111 - val_loss: 0.1681\n",
      "Epoch 561/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0078 - val_loss: 0.1735\n",
      "Epoch 562/1000\n",
      "36324/36324 [==============================] - 36s 999us/step - loss: 0.0088 - val_loss: 0.1637\n",
      "Epoch 563/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0079 - val_loss: 0.1761\n",
      "Epoch 564/1000\n",
      "36324/36324 [==============================] - 64s 2ms/step - loss: 0.0083 - val_loss: 0.1653\n",
      "Epoch 565/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0095 - val_loss: 0.1745\n",
      "Epoch 566/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0097 - val_loss: 0.1768\n",
      "Epoch 567/1000\n",
      "36324/36324 [==============================] - 35s 974us/step - loss: 0.0095 - val_loss: 0.1697\n",
      "Epoch 568/1000\n",
      "36324/36324 [==============================] - 47s 1ms/step - loss: 0.0106 - val_loss: 0.1760\n",
      "Epoch 569/1000\n",
      "36324/36324 [==============================] - 83s 2ms/step - loss: 0.0097 - val_loss: 0.1694\n",
      "Epoch 570/1000\n",
      "36324/36324 [==============================] - 103s 3ms/step - loss: 0.0088 - val_loss: 0.1779\n",
      "Epoch 571/1000\n",
      "36324/36324 [==============================] - 84s 2ms/step - loss: 0.0094 - val_loss: 0.1840\n",
      "Epoch 572/1000\n",
      "36324/36324 [==============================] - 83s 2ms/step - loss: 0.0082 - val_loss: 0.1756\n",
      "Epoch 573/1000\n",
      "36324/36324 [==============================] - 82s 2ms/step - loss: 0.0080 - val_loss: 0.1723\n",
      "Epoch 574/1000\n",
      "36324/36324 [==============================] - 85s 2ms/step - loss: 0.0078 - val_loss: 0.1669\n",
      "Epoch 575/1000\n",
      "36324/36324 [==============================] - 80s 2ms/step - loss: 0.0085 - val_loss: 0.1633\n",
      "Epoch 576/1000\n",
      "36324/36324 [==============================] - 80s 2ms/step - loss: 0.0088 - val_loss: 0.1747\n",
      "Epoch 577/1000\n",
      "36324/36324 [==============================] - 99s 3ms/step - loss: 0.0085 - val_loss: 0.1752\n",
      "Epoch 578/1000\n",
      "36324/36324 [==============================] - 83s 2ms/step - loss: 0.0087 - val_loss: 0.1806\n",
      "Epoch 579/1000\n",
      "36324/36324 [==============================] - 73s 2ms/step - loss: 0.0093 - val_loss: 0.1918\n",
      "Epoch 580/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0099 - val_loss: 0.1783\n",
      "Epoch 581/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0097 - val_loss: 0.1745\n",
      "Epoch 582/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0087 - val_loss: 0.1792\n",
      "Epoch 583/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0087 - val_loss: 0.1729\n",
      "Epoch 584/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0101 - val_loss: 0.1653\n",
      "Epoch 585/1000\n",
      "36324/36324 [==============================] - 35s 970us/step - loss: 0.0090 - val_loss: 0.1719\n",
      "Epoch 586/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0100 - val_loss: 0.1674\n",
      "Epoch 587/1000\n",
      "36324/36324 [==============================] - 36s 996us/step - loss: 0.0109 - val_loss: 0.1873\n",
      "Epoch 588/1000\n",
      "36324/36324 [==============================] - 35s 971us/step - loss: 0.0088 - val_loss: 0.1674\n",
      "Epoch 589/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0087 - val_loss: 0.1622\n",
      "Epoch 590/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0085 - val_loss: 0.1772\n",
      "Epoch 591/1000\n",
      "36324/36324 [==============================] - 35s 963us/step - loss: 0.0080 - val_loss: 0.1821\n",
      "Epoch 592/1000\n",
      "36324/36324 [==============================] - 34s 923us/step - loss: 0.0081 - val_loss: 0.1717\n",
      "Epoch 593/1000\n",
      "36324/36324 [==============================] - 35s 951us/step - loss: 0.0087 - val_loss: 0.1752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 594/1000\n",
      "36324/36324 [==============================] - 56s 2ms/step - loss: 0.0081 - val_loss: 0.1769\n",
      "Epoch 595/1000\n",
      "36324/36324 [==============================] - 80s 2ms/step - loss: 0.0087 - val_loss: 0.1702\n",
      "Epoch 596/1000\n",
      "36324/36324 [==============================] - 105s 3ms/step - loss: 0.0092 - val_loss: 0.1773\n",
      "Epoch 597/1000\n",
      "36324/36324 [==============================] - 87s 2ms/step - loss: 0.0096 - val_loss: 0.1852\n",
      "Epoch 598/1000\n",
      "36324/36324 [==============================] - 79s 2ms/step - loss: 0.0092 - val_loss: 0.1822\n",
      "Epoch 599/1000\n",
      "36324/36324 [==============================] - 86s 2ms/step - loss: 0.0085 - val_loss: 0.1689\n",
      "Epoch 600/1000\n",
      "cooling down to decrease CPU tempereture\n",
      "36324/36324 [==============================] - 415s 11ms/step - loss: 0.0084 - val_loss: 0.1707\n",
      "Epoch 601/1000\n",
      "36324/36324 [==============================] - 85s 2ms/step - loss: 0.0094 - val_loss: 0.1695\n",
      "Epoch 602/1000\n",
      "36324/36324 [==============================] - 78s 2ms/step - loss: 0.0092 - val_loss: 0.1708\n",
      "Epoch 603/1000\n",
      "36324/36324 [==============================] - 93s 3ms/step - loss: 0.0099 - val_loss: 0.1715\n",
      "Epoch 604/1000\n",
      "36324/36324 [==============================] - 78s 2ms/step - loss: 0.0087 - val_loss: 0.1665\n",
      "Epoch 605/1000\n",
      "36324/36324 [==============================] - 76s 2ms/step - loss: 0.0090 - val_loss: 0.1762\n",
      "Epoch 606/1000\n",
      "36324/36324 [==============================] - 78s 2ms/step - loss: 0.0091 - val_loss: 0.1805\n",
      "Epoch 607/1000\n",
      "36324/36324 [==============================] - 84s 2ms/step - loss: 0.0098 - val_loss: 0.1732\n",
      "Epoch 608/1000\n",
      "36324/36324 [==============================] - 76s 2ms/step - loss: 0.0085 - val_loss: 0.1714\n",
      "Epoch 609/1000\n",
      "36324/36324 [==============================] - 79s 2ms/step - loss: 0.0089 - val_loss: 0.1739\n",
      "Epoch 610/1000\n",
      "36324/36324 [==============================] - 85s 2ms/step - loss: 0.0102 - val_loss: 0.1687\n",
      "Epoch 611/1000\n",
      "36324/36324 [==============================] - 72s 2ms/step - loss: 0.0088 - val_loss: 0.1754\n",
      "Epoch 612/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0090 - val_loss: 0.1739\n",
      "Epoch 613/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0081 - val_loss: 0.1788\n",
      "Epoch 614/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0090 - val_loss: 0.1809\n",
      "Epoch 615/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0089 - val_loss: 0.1688\n",
      "Epoch 616/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0090 - val_loss: 0.1839\n",
      "Epoch 617/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0080 - val_loss: 0.1690\n",
      "Epoch 618/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0081 - val_loss: 0.1639\n",
      "Epoch 619/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0088 - val_loss: 0.1754\n",
      "Epoch 620/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0084 - val_loss: 0.1706\n",
      "Epoch 621/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0092 - val_loss: 0.1665\n",
      "Epoch 622/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0084 - val_loss: 0.1785\n",
      "Epoch 623/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0086 - val_loss: 0.1645\n",
      "Epoch 624/1000\n",
      "36324/36324 [==============================] - 44s 1ms/step - loss: 0.0083 - val_loss: 0.1688\n",
      "Epoch 625/1000\n",
      "36324/36324 [==============================] - 36s 991us/step - loss: 0.0074 - val_loss: 0.1730\n",
      "Epoch 626/1000\n",
      "36324/36324 [==============================] - 33s 906us/step - loss: 0.0089 - val_loss: 0.1712\n",
      "Epoch 627/1000\n",
      "36324/36324 [==============================] - 35s 953us/step - loss: 0.0086 - val_loss: 0.1667\n",
      "Epoch 628/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0085 - val_loss: 0.1757\n",
      "Epoch 629/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0083 - val_loss: 0.1701\n",
      "Epoch 630/1000\n",
      "36324/36324 [==============================] - 36s 1ms/step - loss: 0.0082 - val_loss: 0.1636\n",
      "Epoch 631/1000\n",
      "36324/36324 [==============================] - 35s 969us/step - loss: 0.0090 - val_loss: 0.1723\n",
      "Epoch 632/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0082 - val_loss: 0.1788\n",
      "Epoch 633/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0083 - val_loss: 0.1751\n",
      "Epoch 634/1000\n",
      "36324/36324 [==============================] - 34s 932us/step - loss: 0.0084 - val_loss: 0.1636\n",
      "Epoch 635/1000\n",
      "36324/36324 [==============================] - 35s 970us/step - loss: 0.0099 - val_loss: 0.1645\n",
      "Epoch 636/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0086 - val_loss: 0.1734\n",
      "Epoch 637/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0090 - val_loss: 0.1683\n",
      "Epoch 638/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0089 - val_loss: 0.1669\n",
      "Epoch 639/1000\n",
      "36324/36324 [==============================] - 58s 2ms/step - loss: 0.0094 - val_loss: 0.1773\n",
      "Epoch 640/1000\n",
      "36324/36324 [==============================] - 54s 1ms/step - loss: 0.0080 - val_loss: 0.1678\n",
      "Epoch 641/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0083 - val_loss: 0.1675\n",
      "Epoch 642/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0100 - val_loss: 0.1623\n",
      "Epoch 643/1000\n",
      "36324/36324 [==============================] - 36s 992us/step - loss: 0.0106 - val_loss: 0.1648\n",
      "Epoch 644/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0100 - val_loss: 0.1719\n",
      "Epoch 645/1000\n",
      "36324/36324 [==============================] - 33s 919us/step - loss: 0.0088 - val_loss: 0.1675\n",
      "Epoch 646/1000\n",
      "36324/36324 [==============================] - 33s 904us/step - loss: 0.0085 - val_loss: 0.1746\n",
      "Epoch 647/1000\n",
      "36324/36324 [==============================] - 36s 998us/step - loss: 0.0093 - val_loss: 0.1703\n",
      "Epoch 648/1000\n",
      "36324/36324 [==============================] - 43s 1ms/step - loss: 0.0092 - val_loss: 0.1647\n",
      "Epoch 649/1000\n",
      "36324/36324 [==============================] - 34s 949us/step - loss: 0.0090 - val_loss: 0.1758\n",
      "Epoch 650/1000\n",
      "36324/36324 [==============================] - 34s 926us/step - loss: 0.0088 - val_loss: 0.1818\n",
      "Epoch 651/1000\n",
      "36324/36324 [==============================] - 35s 974us/step - loss: 0.0081 - val_loss: 0.1779\n",
      "Epoch 652/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0092 - val_loss: 0.1984\n",
      "Epoch 653/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0079 - val_loss: 0.1762\n",
      "Epoch 654/1000\n",
      "36324/36324 [==============================] - 35s 953us/step - loss: 0.0078 - val_loss: 0.1739\n",
      "Epoch 655/1000\n",
      "36324/36324 [==============================] - 36s 1ms/step - loss: 0.0092 - val_loss: 0.1724\n",
      "Epoch 656/1000\n",
      "36324/36324 [==============================] - 58s 2ms/step - loss: 0.0099 - val_loss: 0.1683\n",
      "Epoch 657/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0087 - val_loss: 0.1728\n",
      "Epoch 658/1000\n",
      "36324/36324 [==============================] - 36s 978us/step - loss: 0.0103 - val_loss: 0.1794\n",
      "Epoch 659/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0118 - val_loss: 0.1908\n",
      "Epoch 660/1000\n",
      "36324/36324 [==============================] - 36s 984us/step - loss: 0.0087 - val_loss: 0.1717\n",
      "Epoch 661/1000\n",
      "36324/36324 [==============================] - 34s 934us/step - loss: 0.0088 - val_loss: 0.1751\n",
      "Epoch 662/1000\n",
      "36324/36324 [==============================] - 35s 966us/step - loss: 0.0080 - val_loss: 0.1689\n",
      "Epoch 663/1000\n",
      "36324/36324 [==============================] - 34s 924us/step - loss: 0.0078 - val_loss: 0.1756\n",
      "Epoch 664/1000\n",
      "36324/36324 [==============================] - 61s 2ms/step - loss: 0.0091 - val_loss: 0.1750\n",
      "Epoch 665/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0094 - val_loss: 0.1681\n",
      "Epoch 666/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0088 - val_loss: 0.1677\n",
      "Epoch 667/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0101 - val_loss: 0.1754\n",
      "Epoch 668/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0086 - val_loss: 0.1674\n",
      "Epoch 669/1000\n",
      "36324/36324 [==============================] - 47s 1ms/step - loss: 0.0080 - val_loss: 0.1707\n",
      "Epoch 670/1000\n",
      "36324/36324 [==============================] - 33s 918us/step - loss: 0.0081 - val_loss: 0.1686\n",
      "Epoch 671/1000\n",
      "36324/36324 [==============================] - 60s 2ms/step - loss: 0.0093 - val_loss: 0.1756\n",
      "Epoch 672/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0090 - val_loss: 0.1724\n",
      "Epoch 673/1000\n",
      "36324/36324 [==============================] - 61s 2ms/step - loss: 0.0086 - val_loss: 0.1696\n",
      "Epoch 674/1000\n",
      "36324/36324 [==============================] - 87s 2ms/step - loss: 0.0094 - val_loss: 0.1870\n",
      "Epoch 675/1000\n",
      "36324/36324 [==============================] - 78s 2ms/step - loss: 0.0090 - val_loss: 0.1682\n",
      "Epoch 676/1000\n",
      "36324/36324 [==============================] - 93s 3ms/step - loss: 0.0076 - val_loss: 0.1693\n",
      "Epoch 677/1000\n",
      "36324/36324 [==============================] - 83s 2ms/step - loss: 0.0093 - val_loss: 0.1734\n",
      "Epoch 678/1000\n",
      "36324/36324 [==============================] - 77s 2ms/step - loss: 0.0074 - val_loss: 0.1775\n",
      "Epoch 679/1000\n",
      "36324/36324 [==============================] - 81s 2ms/step - loss: 0.0078 - val_loss: 0.1699\n",
      "Epoch 680/1000\n",
      "36324/36324 [==============================] - 85s 2ms/step - loss: 0.0099 - val_loss: 0.1840\n",
      "Epoch 681/1000\n",
      "36324/36324 [==============================] - 82s 2ms/step - loss: 0.0078 - val_loss: 0.1663\n",
      "Epoch 682/1000\n",
      "36324/36324 [==============================] - 77s 2ms/step - loss: 0.0090 - val_loss: 0.1825\n",
      "Epoch 683/1000\n",
      "36324/36324 [==============================] - 96s 3ms/step - loss: 0.0087 - val_loss: 0.1765\n",
      "Epoch 684/1000\n",
      "36324/36324 [==============================] - 68s 2ms/step - loss: 0.0089 - val_loss: 0.1812\n",
      "Epoch 685/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0078 - val_loss: 0.1712\n",
      "Epoch 686/1000\n",
      "36324/36324 [==============================] - 36s 983us/step - loss: 0.0101 - val_loss: 0.1717\n",
      "Epoch 687/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0095 - val_loss: 0.1720\n",
      "Epoch 688/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0086 - val_loss: 0.1687\n",
      "Epoch 689/1000\n",
      "36324/36324 [==============================] - 61s 2ms/step - loss: 0.0091 - val_loss: 0.1765\n",
      "Epoch 690/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0084 - val_loss: 0.1717\n",
      "Epoch 691/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0086 - val_loss: 0.1728\n",
      "Epoch 692/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0082 - val_loss: 0.1728\n",
      "Epoch 693/1000\n",
      "36324/36324 [==============================] - 36s 983us/step - loss: 0.0083 - val_loss: 0.1745\n",
      "Epoch 694/1000\n",
      "36324/36324 [==============================] - 32s 874us/step - loss: 0.0091 - val_loss: 0.1696\n",
      "Epoch 695/1000\n",
      "36324/36324 [==============================] - 35s 952us/step - loss: 0.0090 - val_loss: 0.1727\n",
      "Epoch 696/1000\n",
      "36324/36324 [==============================] - 36s 987us/step - loss: 0.0087 - val_loss: 0.1735\n",
      "Epoch 697/1000\n",
      "36324/36324 [==============================] - 46s 1ms/step - loss: 0.0084 - val_loss: 0.1781\n",
      "Epoch 698/1000\n",
      "36324/36324 [==============================] - 70s 2ms/step - loss: 0.0081 - val_loss: 0.1761\n",
      "Epoch 699/1000\n",
      "36324/36324 [==============================] - 80s 2ms/step - loss: 0.0093 - val_loss: 0.1699\n",
      "Epoch 700/1000\n",
      "cooling down to decrease CPU tempereture\n",
      "36324/36324 [==============================] - 368s 10ms/step - loss: 0.0092 - val_loss: 0.1645\n",
      "Epoch 701/1000\n",
      "36324/36324 [==============================] - 49s 1ms/step - loss: 0.0085 - val_loss: 0.1753\n",
      "Epoch 702/1000\n",
      "36324/36324 [==============================] - 54s 1ms/step - loss: 0.0092 - val_loss: 0.1711\n",
      "Epoch 703/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0083 - val_loss: 0.1654\n",
      "Epoch 704/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0088 - val_loss: 0.1701\n",
      "Epoch 705/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0078 - val_loss: 0.1655\n",
      "Epoch 706/1000\n",
      "36324/36324 [==============================] - 35s 975us/step - loss: 0.0081 - val_loss: 0.1826\n",
      "Epoch 707/1000\n",
      "36324/36324 [==============================] - 36s 986us/step - loss: 0.0091 - val_loss: 0.1717\n",
      "Epoch 708/1000\n",
      "36324/36324 [==============================] - 33s 905us/step - loss: 0.0092 - val_loss: 0.1790\n",
      "Epoch 709/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0089 - val_loss: 0.1714\n",
      "Epoch 710/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0079 - val_loss: 0.1575\n",
      "Epoch 711/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0096 - val_loss: 0.1732\n",
      "Epoch 712/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0080 - val_loss: 0.2042\n",
      "Epoch 713/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0094 - val_loss: 0.1916\n",
      "Epoch 714/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0079 - val_loss: 0.1741\n",
      "Epoch 715/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0079 - val_loss: 0.1707\n",
      "Epoch 716/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0098 - val_loss: 0.1721\n",
      "Epoch 717/1000\n",
      "36324/36324 [==============================] - 63s 2ms/step - loss: 0.0078 - val_loss: 0.1721\n",
      "Epoch 718/1000\n",
      "36324/36324 [==============================] - 44s 1ms/step - loss: 0.0094 - val_loss: 0.1770\n",
      "Epoch 719/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0097 - val_loss: 0.1799\n",
      "Epoch 720/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0089 - val_loss: 0.1636\n",
      "Epoch 721/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0085 - val_loss: 0.1696\n",
      "Epoch 722/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0078 - val_loss: 0.1738\n",
      "Epoch 723/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0091 - val_loss: 0.1736\n",
      "Epoch 724/1000\n",
      "36324/36324 [==============================] - 61s 2ms/step - loss: 0.0083 - val_loss: 0.1789\n",
      "Epoch 725/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0086 - val_loss: 0.1672\n",
      "Epoch 726/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0090 - val_loss: 0.1770\n",
      "Epoch 727/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0084 - val_loss: 0.1692\n",
      "Epoch 728/1000\n",
      "36324/36324 [==============================] - 36s 1ms/step - loss: 0.0078 - val_loss: 0.1665\n",
      "Epoch 729/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0083 - val_loss: 0.1711\n",
      "Epoch 730/1000\n",
      "36324/36324 [==============================] - 36s 995us/step - loss: 0.0088 - val_loss: 0.1667\n",
      "Epoch 731/1000\n",
      "36324/36324 [==============================] - 35s 962us/step - loss: 0.0101 - val_loss: 0.1684\n",
      "Epoch 732/1000\n",
      "36324/36324 [==============================] - 43s 1ms/step - loss: 0.0076 - val_loss: 0.1669\n",
      "Epoch 733/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0086 - val_loss: 0.1638\n",
      "Epoch 734/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0093 - val_loss: 0.1709\n",
      "Epoch 735/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0095 - val_loss: 0.1812\n",
      "Epoch 736/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0082 - val_loss: 0.1656\n",
      "Epoch 737/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0087 - val_loss: 0.1776\n",
      "Epoch 738/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0092 - val_loss: 0.1707\n",
      "Epoch 739/1000\n",
      "36324/36324 [==============================] - 51s 1ms/step - loss: 0.0089 - val_loss: 0.1736\n",
      "Epoch 740/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0090 - val_loss: 0.1783\n",
      "Epoch 741/1000\n",
      "36324/36324 [==============================] - 35s 960us/step - loss: 0.0082 - val_loss: 0.1755\n",
      "Epoch 742/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36324/36324 [==============================] - 36s 995us/step - loss: 0.0088 - val_loss: 0.1671\n",
      "Epoch 743/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0079 - val_loss: 0.1789\n",
      "Epoch 744/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0085 - val_loss: 0.1778\n",
      "Epoch 745/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0089 - val_loss: 0.1765\n",
      "Epoch 746/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0086 - val_loss: 0.1744\n",
      "Epoch 747/1000\n",
      "36324/36324 [==============================] - 49s 1ms/step - loss: 0.0117 - val_loss: 0.1702\n",
      "Epoch 748/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0089 - val_loss: 0.1823\n",
      "Epoch 749/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0084 - val_loss: 0.1665\n",
      "Epoch 750/1000\n",
      "36324/36324 [==============================] - 36s 978us/step - loss: 0.0085 - val_loss: 0.1722\n",
      "Epoch 751/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0089 - val_loss: 0.1685\n",
      "Epoch 752/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0082 - val_loss: 0.1678\n",
      "Epoch 753/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0085 - val_loss: 0.1656\n",
      "Epoch 754/1000\n",
      "36324/36324 [==============================] - 45s 1ms/step - loss: 0.0087 - val_loss: 0.1703\n",
      "Epoch 755/1000\n",
      "36324/36324 [==============================] - 44s 1ms/step - loss: 0.0081 - val_loss: 0.1754\n",
      "Epoch 756/1000\n",
      "36324/36324 [==============================] - 36s 995us/step - loss: 0.0102 - val_loss: 0.1844\n",
      "Epoch 757/1000\n",
      "36324/36324 [==============================] - 36s 1ms/step - loss: 0.0086 - val_loss: 0.1706\n",
      "Epoch 758/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0084 - val_loss: 0.1651\n",
      "Epoch 759/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0073 - val_loss: 0.1685\n",
      "Epoch 760/1000\n",
      "36324/36324 [==============================] - 35s 968us/step - loss: 0.0078 - val_loss: 0.1661\n",
      "Epoch 761/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0078 - val_loss: 0.1741\n",
      "Epoch 762/1000\n",
      "36324/36324 [==============================] - 45s 1ms/step - loss: 0.0091 - val_loss: 0.1710\n",
      "Epoch 763/1000\n",
      "36324/36324 [==============================] - 69s 2ms/step - loss: 0.0070 - val_loss: 0.1733\n",
      "Epoch 764/1000\n",
      "36324/36324 [==============================] - 89s 2ms/step - loss: 0.0084 - val_loss: 0.1677\n",
      "Epoch 765/1000\n",
      "36324/36324 [==============================] - 83s 2ms/step - loss: 0.0082 - val_loss: 0.1755\n",
      "Epoch 766/1000\n",
      "36324/36324 [==============================] - 81s 2ms/step - loss: 0.0085 - val_loss: 0.1776\n",
      "Epoch 767/1000\n",
      "36324/36324 [==============================] - 88s 2ms/step - loss: 0.0101 - val_loss: 0.1730\n",
      "Epoch 768/1000\n",
      "36324/36324 [==============================] - 81s 2ms/step - loss: 0.0081 - val_loss: 0.1841\n",
      "Epoch 769/1000\n",
      "36324/36324 [==============================] - 80s 2ms/step - loss: 0.0077 - val_loss: 0.1755\n",
      "Epoch 770/1000\n",
      "36324/36324 [==============================] - 96s 3ms/step - loss: 0.0077 - val_loss: 0.1813\n",
      "Epoch 771/1000\n",
      "36324/36324 [==============================] - 184s 5ms/step - loss: 0.0079 - val_loss: 0.1832\n",
      "Epoch 772/1000\n",
      "36324/36324 [==============================] - 81s 2ms/step - loss: 0.0090 - val_loss: 0.1728\n",
      "Epoch 773/1000\n",
      "36324/36324 [==============================] - 98s 3ms/step - loss: 0.0086 - val_loss: 0.1677\n",
      "Epoch 774/1000\n",
      "36324/36324 [==============================] - 84s 2ms/step - loss: 0.0086 - val_loss: 0.1630\n",
      "Epoch 775/1000\n",
      "36324/36324 [==============================] - 79s 2ms/step - loss: 0.0085 - val_loss: 0.1813\n",
      "Epoch 776/1000\n",
      "36324/36324 [==============================] - 107s 3ms/step - loss: 0.0086 - val_loss: 0.1729\n",
      "Epoch 777/1000\n",
      "36324/36324 [==============================] - 81s 2ms/step - loss: 0.0078 - val_loss: 0.1719\n",
      "Epoch 778/1000\n",
      "36324/36324 [==============================] - 78s 2ms/step - loss: 0.0084 - val_loss: 0.1898\n",
      "Epoch 779/1000\n",
      "36324/36324 [==============================] - 78s 2ms/step - loss: 0.0081 - val_loss: 0.1664\n",
      "Epoch 780/1000\n",
      "36324/36324 [==============================] - 43s 1ms/step - loss: 0.0079 - val_loss: 0.1697\n",
      "Epoch 781/1000\n",
      "36324/36324 [==============================] - 35s 964us/step - loss: 0.0075 - val_loss: 0.1647\n",
      "Epoch 782/1000\n",
      "36324/36324 [==============================] - 36s 992us/step - loss: 0.0085 - val_loss: 0.1585\n",
      "Epoch 783/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0083 - val_loss: 0.1720\n",
      "Epoch 784/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0080 - val_loss: 0.1629\n",
      "Epoch 785/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0085 - val_loss: 0.1632\n",
      "Epoch 786/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0091 - val_loss: 0.1797\n",
      "Epoch 787/1000\n",
      "36324/36324 [==============================] - 62s 2ms/step - loss: 0.0083 - val_loss: 0.1695\n",
      "Epoch 788/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0086 - val_loss: 0.1716\n",
      "Epoch 789/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0089 - val_loss: 0.1784\n",
      "Epoch 790/1000\n",
      "36324/36324 [==============================] - 48s 1ms/step - loss: 0.0099 - val_loss: 0.1762\n",
      "Epoch 791/1000\n",
      "36324/36324 [==============================] - 83s 2ms/step - loss: 0.0102 - val_loss: 0.1702\n",
      "Epoch 792/1000\n",
      "36324/36324 [==============================] - 82s 2ms/step - loss: 0.0085 - val_loss: 0.1685\n",
      "Epoch 793/1000\n",
      "36324/36324 [==============================] - 93s 3ms/step - loss: 0.0082 - val_loss: 0.1640\n",
      "Epoch 794/1000\n",
      "36324/36324 [==============================] - 78s 2ms/step - loss: 0.0087 - val_loss: 0.1764\n",
      "Epoch 795/1000\n",
      "36324/36324 [==============================] - 79s 2ms/step - loss: 0.0080 - val_loss: 0.1729\n",
      "Epoch 796/1000\n",
      "36324/36324 [==============================] - 100s 3ms/step - loss: 0.0083 - val_loss: 0.1696\n",
      "Epoch 797/1000\n",
      "36324/36324 [==============================] - 177s 5ms/step - loss: 0.0087 - val_loss: 0.1840\n",
      "Epoch 798/1000\n",
      "36324/36324 [==============================] - 80s 2ms/step - loss: 0.0084 - val_loss: 0.1878\n",
      "Epoch 799/1000\n",
      "36324/36324 [==============================] - 150s 4ms/step - loss: 0.0089 - val_loss: 0.1802\n",
      "Epoch 800/1000\n",
      "cooling down to decrease CPU tempereture\n",
      "36324/36324 [==============================] - 422s 12ms/step - loss: 0.0079 - val_loss: 0.1751\n",
      "Epoch 801/1000\n",
      "36324/36324 [==============================] - 107s 3ms/step - loss: 0.0080 - val_loss: 0.1590\n",
      "Epoch 802/1000\n",
      "36324/36324 [==============================] - 84s 2ms/step - loss: 0.0095 - val_loss: 0.1763\n",
      "Epoch 803/1000\n",
      "36324/36324 [==============================] - 81s 2ms/step - loss: 0.0076 - val_loss: 0.1727\n",
      "Epoch 804/1000\n",
      "36324/36324 [==============================] - 67s 2ms/step - loss: 0.0082 - val_loss: 0.1718\n",
      "Epoch 805/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0090 - val_loss: 0.1623\n",
      "Epoch 806/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0092 - val_loss: 0.1718\n",
      "Epoch 807/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0113 - val_loss: 0.1710\n",
      "Epoch 808/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0086 - val_loss: 0.1721\n",
      "Epoch 809/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0074 - val_loss: 0.1732\n",
      "Epoch 810/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0086 - val_loss: 0.1743\n",
      "Epoch 811/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0094 - val_loss: 0.1626\n",
      "Epoch 812/1000\n",
      "36324/36324 [==============================] - 46s 1ms/step - loss: 0.0082 - val_loss: 0.1663\n",
      "Epoch 813/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0083 - val_loss: 0.1725\n",
      "Epoch 814/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0096 - val_loss: 0.1800\n",
      "Epoch 815/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0079 - val_loss: 0.1757\n",
      "Epoch 816/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0079 - val_loss: 0.1681\n",
      "Epoch 817/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0085 - val_loss: 0.1702\n",
      "Epoch 818/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0081 - val_loss: 0.1821\n",
      "Epoch 819/1000\n",
      "36324/36324 [==============================] - 61s 2ms/step - loss: 0.0085 - val_loss: 0.1668\n",
      "Epoch 820/1000\n",
      "36324/36324 [==============================] - 45s 1ms/step - loss: 0.0082 - val_loss: 0.1750\n",
      "Epoch 821/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0088 - val_loss: 0.1673\n",
      "Epoch 822/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0099 - val_loss: 0.1721\n",
      "Epoch 823/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0084 - val_loss: 0.1812\n",
      "Epoch 824/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0078 - val_loss: 0.1745\n",
      "Epoch 825/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0077 - val_loss: 0.1797\n",
      "Epoch 826/1000\n",
      "36324/36324 [==============================] - 65s 2ms/step - loss: 0.0075 - val_loss: 0.1752\n",
      "Epoch 827/1000\n",
      "36324/36324 [==============================] - 85s 2ms/step - loss: 0.0083 - val_loss: 0.1647\n",
      "Epoch 828/1000\n",
      "36324/36324 [==============================] - 81s 2ms/step - loss: 0.0076 - val_loss: 0.1673\n",
      "Epoch 829/1000\n",
      "36324/36324 [==============================] - 85s 2ms/step - loss: 0.0069 - val_loss: 0.1690\n",
      "Epoch 830/1000\n",
      "36324/36324 [==============================] - 111s 3ms/step - loss: 0.0080 - val_loss: 0.1790\n",
      "Epoch 831/1000\n",
      "36324/36324 [==============================] - 50s 1ms/step - loss: 0.0075 - val_loss: 0.1746\n",
      "Epoch 832/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0084 - val_loss: 0.1635\n",
      "Epoch 833/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0075 - val_loss: 0.1673\n",
      "Epoch 834/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0071 - val_loss: 0.1675\n",
      "Epoch 835/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0083 - val_loss: 0.1682\n",
      "Epoch 836/1000\n",
      "36324/36324 [==============================] - 46s 1ms/step - loss: 0.0079 - val_loss: 0.1687\n",
      "Epoch 837/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0077 - val_loss: 0.1664\n",
      "Epoch 838/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0094 - val_loss: 0.1644\n",
      "Epoch 839/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0104 - val_loss: 0.1893\n",
      "Epoch 840/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0083 - val_loss: 0.1742\n",
      "Epoch 841/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0079 - val_loss: 0.1733\n",
      "Epoch 842/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0077 - val_loss: 0.1688\n",
      "Epoch 843/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0078 - val_loss: 0.1747\n",
      "Epoch 844/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0082 - val_loss: 0.1757\n",
      "Epoch 845/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0078 - val_loss: 0.1711\n",
      "Epoch 846/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0089 - val_loss: 0.1841\n",
      "Epoch 847/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0077 - val_loss: 0.1778\n",
      "Epoch 848/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0078 - val_loss: 0.1705\n",
      "Epoch 849/1000\n",
      "36324/36324 [==============================] - 36s 994us/step - loss: 0.0079 - val_loss: 0.1766\n",
      "Epoch 850/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0090 - val_loss: 0.1803\n",
      "Epoch 851/1000\n",
      "36324/36324 [==============================] - 45s 1ms/step - loss: 0.0101 - val_loss: 0.1852\n",
      "Epoch 852/1000\n",
      "36324/36324 [==============================] - 66s 2ms/step - loss: 0.0080 - val_loss: 0.1736\n",
      "Epoch 853/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0099 - val_loss: 0.1677\n",
      "Epoch 854/1000\n",
      "36324/36324 [==============================] - 36s 1000us/step - loss: 0.0090 - val_loss: 0.1630\n",
      "Epoch 855/1000\n",
      "36324/36324 [==============================] - 33s 900us/step - loss: 0.0077 - val_loss: 0.1741\n",
      "Epoch 856/1000\n",
      "36324/36324 [==============================] - 35s 959us/step - loss: 0.0080 - val_loss: 0.1709\n",
      "Epoch 857/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0080 - val_loss: 0.1806\n",
      "Epoch 858/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0093 - val_loss: 0.1716\n",
      "Epoch 859/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0075 - val_loss: 0.1770\n",
      "Epoch 860/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0087 - val_loss: 0.1643\n",
      "Epoch 861/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0091 - val_loss: 0.1830\n",
      "Epoch 862/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0088 - val_loss: 0.1688\n",
      "Epoch 863/1000\n",
      "36324/36324 [==============================] - 36s 992us/step - loss: 0.0087 - val_loss: 0.1734\n",
      "Epoch 864/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0088 - val_loss: 0.1610\n",
      "Epoch 865/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0094 - val_loss: 0.1655\n",
      "Epoch 866/1000\n",
      "36324/36324 [==============================] - 44s 1ms/step - loss: 0.0081 - val_loss: 0.1754\n",
      "Epoch 867/1000\n",
      "36324/36324 [==============================] - 35s 971us/step - loss: 0.0087 - val_loss: 0.1786\n",
      "Epoch 868/1000\n",
      "36324/36324 [==============================] - 34s 946us/step - loss: 0.0101 - val_loss: 0.1849\n",
      "Epoch 869/1000\n",
      "36324/36324 [==============================] - 34s 940us/step - loss: 0.0092 - val_loss: 0.1895\n",
      "Epoch 870/1000\n",
      "36324/36324 [==============================] - 35s 962us/step - loss: 0.0079 - val_loss: 0.1788\n",
      "Epoch 871/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0082 - val_loss: 0.1737\n",
      "Epoch 872/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0079 - val_loss: 0.1719\n",
      "Epoch 873/1000\n",
      "36324/36324 [==============================] - 36s 1ms/step - loss: 0.0086 - val_loss: 0.1717\n",
      "Epoch 874/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0074 - val_loss: 0.1726\n",
      "Epoch 875/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0070 - val_loss: 0.1686\n",
      "Epoch 876/1000\n",
      "36324/36324 [==============================] - 36s 986us/step - loss: 0.0073 - val_loss: 0.1803\n",
      "Epoch 877/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0071 - val_loss: 0.1858\n",
      "Epoch 878/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0077 - val_loss: 0.1668\n",
      "Epoch 879/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0081 - val_loss: 0.1598\n",
      "Epoch 880/1000\n",
      "36324/36324 [==============================] - 35s 951us/step - loss: 0.0083 - val_loss: 0.1679\n",
      "Epoch 881/1000\n",
      "36324/36324 [==============================] - 36s 1ms/step - loss: 0.0081 - val_loss: 0.1687\n",
      "Epoch 882/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0077 - val_loss: 0.1910\n",
      "Epoch 883/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0076 - val_loss: 0.1789\n",
      "Epoch 884/1000\n",
      "36324/36324 [==============================] - 34s 948us/step - loss: 0.0078 - val_loss: 0.1910\n",
      "Epoch 885/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0085 - val_loss: 0.1731\n",
      "Epoch 886/1000\n",
      "36324/36324 [==============================] - 34s 929us/step - loss: 0.0087 - val_loss: 0.1755\n",
      "Epoch 887/1000\n",
      "36324/36324 [==============================] - 35s 962us/step - loss: 0.0083 - val_loss: 0.1756\n",
      "Epoch 888/1000\n",
      "36324/36324 [==============================] - 36s 984us/step - loss: 0.0077 - val_loss: 0.1700\n",
      "Epoch 889/1000\n",
      "36324/36324 [==============================] - 35s 974us/step - loss: 0.0092 - val_loss: 0.1838\n",
      "Epoch 890/1000\n",
      "36324/36324 [==============================] - 43s 1ms/step - loss: 0.0090 - val_loss: 0.1829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 891/1000\n",
      "36324/36324 [==============================] - 47s 1ms/step - loss: 0.0089 - val_loss: 0.1756\n",
      "Epoch 892/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0091 - val_loss: 0.1884\n",
      "Epoch 893/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0082 - val_loss: 0.1780\n",
      "Epoch 894/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0078 - val_loss: 0.1712\n",
      "Epoch 895/1000\n",
      "36324/36324 [==============================] - 36s 999us/step - loss: 0.0086 - val_loss: 0.1793\n",
      "Epoch 896/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0086 - val_loss: 0.1697\n",
      "Epoch 897/1000\n",
      "36324/36324 [==============================] - 53s 1ms/step - loss: 0.0087 - val_loss: 0.1683\n",
      "Epoch 898/1000\n",
      "36324/36324 [==============================] - 106s 3ms/step - loss: 0.0091 - val_loss: 0.1825\n",
      "Epoch 899/1000\n",
      "36324/36324 [==============================] - 85s 2ms/step - loss: 0.0076 - val_loss: 0.1690\n",
      "Epoch 900/1000\n",
      "cooling down to decrease CPU tempereture\n",
      "36324/36324 [==============================] - 371s 10ms/step - loss: 0.0085 - val_loss: 0.1803\n",
      "Epoch 901/1000\n",
      "36324/36324 [==============================] - 44s 1ms/step - loss: 0.0074 - val_loss: 0.1755\n",
      "Epoch 902/1000\n",
      "36324/36324 [==============================] - 45s 1ms/step - loss: 0.0086 - val_loss: 0.1788\n",
      "Epoch 903/1000\n",
      "36324/36324 [==============================] - 36s 1ms/step - loss: 0.0084 - val_loss: 0.1647\n",
      "Epoch 904/1000\n",
      "36324/36324 [==============================] - 36s 997us/step - loss: 0.0092 - val_loss: 0.1740\n",
      "Epoch 905/1000\n",
      "36324/36324 [==============================] - 35s 959us/step - loss: 0.0087 - val_loss: 0.1791\n",
      "Epoch 906/1000\n",
      "36324/36324 [==============================] - 35s 962us/step - loss: 0.0079 - val_loss: 0.1694\n",
      "Epoch 907/1000\n",
      "36324/36324 [==============================] - 36s 980us/step - loss: 0.0080 - val_loss: 0.1606\n",
      "Epoch 908/1000\n",
      "36324/36324 [==============================] - 36s 993us/step - loss: 0.0088 - val_loss: 0.1662\n",
      "Epoch 909/1000\n",
      "36324/36324 [==============================] - 36s 991us/step - loss: 0.0097 - val_loss: 0.1856\n",
      "Epoch 910/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0085 - val_loss: 0.1728\n",
      "Epoch 911/1000\n",
      "36324/36324 [==============================] - 43s 1ms/step - loss: 0.0088 - val_loss: 0.1784\n",
      "Epoch 912/1000\n",
      "36324/36324 [==============================] - 36s 988us/step - loss: 0.0082 - val_loss: 0.1756\n",
      "Epoch 913/1000\n",
      "36324/36324 [==============================] - 33s 920us/step - loss: 0.0077 - val_loss: 0.1714\n",
      "Epoch 914/1000\n",
      "36324/36324 [==============================] - 34s 942us/step - loss: 0.0089 - val_loss: 0.1650\n",
      "Epoch 915/1000\n",
      "36324/36324 [==============================] - 32s 892us/step - loss: 0.0075 - val_loss: 0.1810\n",
      "Epoch 916/1000\n",
      "36324/36324 [==============================] - 34s 947us/step - loss: 0.0094 - val_loss: 0.1687\n",
      "Epoch 917/1000\n",
      "36324/36324 [==============================] - 35s 962us/step - loss: 0.0080 - val_loss: 0.1665\n",
      "Epoch 918/1000\n",
      "36324/36324 [==============================] - 47s 1ms/step - loss: 0.0079 - val_loss: 0.1651\n",
      "Epoch 919/1000\n",
      "36324/36324 [==============================] - 44s 1ms/step - loss: 0.0074 - val_loss: 0.1680\n",
      "Epoch 920/1000\n",
      "36324/36324 [==============================] - 35s 952us/step - loss: 0.0070 - val_loss: 0.1683\n",
      "Epoch 921/1000\n",
      "36324/36324 [==============================] - 36s 987us/step - loss: 0.0097 - val_loss: 0.1794\n",
      "Epoch 922/1000\n",
      "36324/36324 [==============================] - 35s 953us/step - loss: 0.0084 - val_loss: 0.1819\n",
      "Epoch 923/1000\n",
      "36324/36324 [==============================] - 35s 966us/step - loss: 0.0082 - val_loss: 0.1800\n",
      "Epoch 924/1000\n",
      "36324/36324 [==============================] - 34s 927us/step - loss: 0.0081 - val_loss: 0.1787\n",
      "Epoch 925/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0078 - val_loss: 0.1724\n",
      "Epoch 926/1000\n",
      "36324/36324 [==============================] - 36s 994us/step - loss: 0.0078 - val_loss: 0.1703\n",
      "Epoch 927/1000\n",
      "36324/36324 [==============================] - 61s 2ms/step - loss: 0.0085 - val_loss: 0.1657\n",
      "Epoch 928/1000\n",
      "36324/36324 [==============================] - 35s 970us/step - loss: 0.0076 - val_loss: 0.1809\n",
      "Epoch 929/1000\n",
      "36324/36324 [==============================] - 36s 992us/step - loss: 0.0077 - val_loss: 0.1668\n",
      "Epoch 930/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0075 - val_loss: 0.1712\n",
      "Epoch 931/1000\n",
      "36324/36324 [==============================] - 35s 952us/step - loss: 0.0081 - val_loss: 0.1670\n",
      "Epoch 932/1000\n",
      "36324/36324 [==============================] - 34s 941us/step - loss: 0.0105 - val_loss: 0.1872\n",
      "Epoch 933/1000\n",
      "36324/36324 [==============================] - 35s 970us/step - loss: 0.0092 - val_loss: 0.1697\n",
      "Epoch 934/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0087 - val_loss: 0.1739\n",
      "Epoch 935/1000\n",
      "36324/36324 [==============================] - 50s 1ms/step - loss: 0.0091 - val_loss: 0.1777\n",
      "Epoch 936/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0077 - val_loss: 0.1643\n",
      "Epoch 937/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0075 - val_loss: 0.1758\n",
      "Epoch 938/1000\n",
      "36324/36324 [==============================] - 34s 941us/step - loss: 0.0077 - val_loss: 0.1801\n",
      "Epoch 939/1000\n",
      "36324/36324 [==============================] - 34s 944us/step - loss: 0.0080 - val_loss: 0.1759\n",
      "Epoch 940/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0078 - val_loss: 0.1699\n",
      "Epoch 941/1000\n",
      "36324/36324 [==============================] - 60s 2ms/step - loss: 0.0085 - val_loss: 0.1679\n",
      "Epoch 942/1000\n",
      "36324/36324 [==============================] - 47s 1ms/step - loss: 0.0083 - val_loss: 0.1705\n",
      "Epoch 943/1000\n",
      "36324/36324 [==============================] - 34s 947us/step - loss: 0.0078 - val_loss: 0.1764\n",
      "Epoch 944/1000\n",
      "36324/36324 [==============================] - 32s 879us/step - loss: 0.0083 - val_loss: 0.1686\n",
      "Epoch 945/1000\n",
      "36324/36324 [==============================] - 34s 938us/step - loss: 0.0076 - val_loss: 0.1779\n",
      "Epoch 946/1000\n",
      "36324/36324 [==============================] - 34s 938us/step - loss: 0.0073 - val_loss: 0.1687\n",
      "Epoch 947/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0089 - val_loss: 0.1718\n",
      "Epoch 948/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0085 - val_loss: 0.1730\n",
      "Epoch 949/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0077 - val_loss: 0.1762\n",
      "Epoch 950/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0074 - val_loss: 0.1663\n",
      "Epoch 951/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0074 - val_loss: 0.1777\n",
      "Epoch 952/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0080 - val_loss: 0.1755\n",
      "Epoch 953/1000\n",
      "36324/36324 [==============================] - 34s 923us/step - loss: 0.0084 - val_loss: 0.1764\n",
      "Epoch 954/1000\n",
      "36324/36324 [==============================] - 34s 933us/step - loss: 0.0083 - val_loss: 0.1839\n",
      "Epoch 955/1000\n",
      "36324/36324 [==============================] - 35s 955us/step - loss: 0.0082 - val_loss: 0.1691\n",
      "Epoch 956/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0077 - val_loss: 0.1675\n",
      "Epoch 957/1000\n",
      "36324/36324 [==============================] - 36s 999us/step - loss: 0.0082 - val_loss: 0.1653\n",
      "Epoch 958/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0086 - val_loss: 0.1787\n",
      "Epoch 959/1000\n",
      "36324/36324 [==============================] - 43s 1ms/step - loss: 0.0078 - val_loss: 0.1707\n",
      "Epoch 960/1000\n",
      "36324/36324 [==============================] - 33s 904us/step - loss: 0.0082 - val_loss: 0.1788\n",
      "Epoch 961/1000\n",
      "36324/36324 [==============================] - 36s 984us/step - loss: 0.0080 - val_loss: 0.1744\n",
      "Epoch 962/1000\n",
      "36324/36324 [==============================] - 36s 988us/step - loss: 0.0081 - val_loss: 0.1777\n",
      "Epoch 963/1000\n",
      "36324/36324 [==============================] - 35s 962us/step - loss: 0.0087 - val_loss: 0.1730\n",
      "Epoch 964/1000\n",
      "36324/36324 [==============================] - 35s 960us/step - loss: 0.0087 - val_loss: 0.1738\n",
      "Epoch 965/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36324/36324 [==============================] - 34s 928us/step - loss: 0.0085 - val_loss: 0.1615\n",
      "Epoch 966/1000\n",
      "36324/36324 [==============================] - 33s 898us/step - loss: 0.0087 - val_loss: 0.1793\n",
      "Epoch 967/1000\n",
      "36324/36324 [==============================] - 40s 1ms/step - loss: 0.0084 - val_loss: 0.1780\n",
      "Epoch 968/1000\n",
      "36324/36324 [==============================] - 35s 957us/step - loss: 0.0087 - val_loss: 0.1762\n",
      "Epoch 969/1000\n",
      "36324/36324 [==============================] - 33s 900us/step - loss: 0.0074 - val_loss: 0.1724\n",
      "Epoch 970/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0078 - val_loss: 0.1790\n",
      "Epoch 971/1000\n",
      "36324/36324 [==============================] - 36s 994us/step - loss: 0.0087 - val_loss: 0.1673\n",
      "Epoch 972/1000\n",
      "36324/36324 [==============================] - 36s 987us/step - loss: 0.0087 - val_loss: 0.1847\n",
      "Epoch 973/1000\n",
      "36324/36324 [==============================] - 35s 961us/step - loss: 0.0078 - val_loss: 0.1652\n",
      "Epoch 974/1000\n",
      "36324/36324 [==============================] - 34s 947us/step - loss: 0.0085 - val_loss: 0.1735\n",
      "Epoch 975/1000\n",
      "36324/36324 [==============================] - 36s 996us/step - loss: 0.0083 - val_loss: 0.1714\n",
      "Epoch 976/1000\n",
      "36324/36324 [==============================] - 43s 1ms/step - loss: 0.0088 - val_loss: 0.1729\n",
      "Epoch 977/1000\n",
      "36324/36324 [==============================] - 34s 948us/step - loss: 0.0077 - val_loss: 0.1710\n",
      "Epoch 978/1000\n",
      "36324/36324 [==============================] - 41s 1ms/step - loss: 0.0083 - val_loss: 0.1777\n",
      "Epoch 979/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0086 - val_loss: 0.1728\n",
      "Epoch 980/1000\n",
      "36324/36324 [==============================] - 34s 939us/step - loss: 0.0088 - val_loss: 0.1702\n",
      "Epoch 981/1000\n",
      "36324/36324 [==============================] - 35s 958us/step - loss: 0.0073 - val_loss: 0.1694\n",
      "Epoch 982/1000\n",
      "36324/36324 [==============================] - 34s 946us/step - loss: 0.0079 - val_loss: 0.1846\n",
      "Epoch 983/1000\n",
      "36324/36324 [==============================] - 33s 912us/step - loss: 0.0077 - val_loss: 0.1734\n",
      "Epoch 984/1000\n",
      "36324/36324 [==============================] - 57s 2ms/step - loss: 0.0072 - val_loss: 0.1691\n",
      "Epoch 985/1000\n",
      "36324/36324 [==============================] - 36s 984us/step - loss: 0.0080 - val_loss: 0.1612\n",
      "Epoch 986/1000\n",
      "36324/36324 [==============================] - 33s 902us/step - loss: 0.0080 - val_loss: 0.1671\n",
      "Epoch 987/1000\n",
      "36324/36324 [==============================] - 32s 891us/step - loss: 0.0080 - val_loss: 0.1758\n",
      "Epoch 988/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0071 - val_loss: 0.1640\n",
      "Epoch 989/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0086 - val_loss: 0.1722\n",
      "Epoch 990/1000\n",
      "36324/36324 [==============================] - 34s 942us/step - loss: 0.0076 - val_loss: 0.1719\n",
      "Epoch 991/1000\n",
      "36324/36324 [==============================] - 33s 920us/step - loss: 0.0080 - val_loss: 0.1708\n",
      "Epoch 992/1000\n",
      "36324/36324 [==============================] - 57s 2ms/step - loss: 0.0080 - val_loss: 0.1686\n",
      "Epoch 993/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0079 - val_loss: 0.1716\n",
      "Epoch 994/1000\n",
      "36324/36324 [==============================] - 38s 1ms/step - loss: 0.0085 - val_loss: 0.1700\n",
      "Epoch 995/1000\n",
      "36324/36324 [==============================] - 35s 971us/step - loss: 0.0078 - val_loss: 0.1818\n",
      "Epoch 996/1000\n",
      "36324/36324 [==============================] - 37s 1ms/step - loss: 0.0086 - val_loss: 0.1693\n",
      "Epoch 997/1000\n",
      "36324/36324 [==============================] - 39s 1ms/step - loss: 0.0079 - val_loss: 0.1835\n",
      "Epoch 998/1000\n",
      "36324/36324 [==============================] - 42s 1ms/step - loss: 0.0081 - val_loss: 0.1704\n",
      "Epoch 999/1000\n",
      "36324/36324 [==============================] - 102s 3ms/step - loss: 0.0086 - val_loss: 0.1693\n",
      "Epoch 1000/1000\n",
      "cooling down to decrease CPU tempereture\n",
      "36324/36324 [==============================] - 429s 12ms/step - loss: 0.0076 - val_loss: 0.1769\n",
      "time took 14:13:57.834811\n"
     ]
    }
   ],
   "source": [
    "start=dt.datetime.now()\n",
    "model.compile(loss='mse', optimizer='Adam')\n",
    "import time\n",
    "import keras\n",
    "class delay(keras.callbacks.Callback):\n",
    "    def __int__(self,delay_time=600):\n",
    "        sel.delay_time = 600\n",
    "        \n",
    "    def on_epoch_begin(self,epoch,logs={}):\n",
    "        if(epoch+1)%100==0:\n",
    "            print(\"cooling down to decrease CPU tempereture\")\n",
    "            time.sleep(300)#600 sec\n",
    "results=model.fit(train_im,train_ang,epochs=1000,batch_size=512,validation_data=(val_im,val_ang),verbose=1,callbacks=[delay()])\n",
    "print(\"time took\",dt.datetime.now()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Best_model_One/mymodel_best_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(results.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_csv_file = 'Best_model_One/history.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_json_file = 'Best_model_One/history.json' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    df.to_json(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_excel = df.to_excel (r'Best_model_One/export_dataframe.xlsx', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36324/36324 [==============================] - 77s 2ms/step\n",
      "loss on train data::\n",
      "0.0022747963839580675\n",
      "9082/9082 [==============================] - 12s 1ms/step\n",
      "loss on test data::\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17691543988013494"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.evaluate(train_im, train_ang, verbose=1)\n",
    "print(\"loss on train data::\")\n",
    "print(scores)\n",
    "scores = model.evaluate(val_im, val_ang, verbose=1)\n",
    "print(\"loss on test data::\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(results.history['loss'])\n",
    "plt.plot(results.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.203225</td>\n",
       "      <td>0.264360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.237757</td>\n",
       "      <td>0.200286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.263508</td>\n",
       "      <td>0.139577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.314412</td>\n",
       "      <td>0.098040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.267303</td>\n",
       "      <td>0.099887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.244712</td>\n",
       "      <td>0.068521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.219361</td>\n",
       "      <td>0.064429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.206102</td>\n",
       "      <td>0.047933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.221745</td>\n",
       "      <td>0.043400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.252096</td>\n",
       "      <td>0.041663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.183848</td>\n",
       "      <td>0.044997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.203825</td>\n",
       "      <td>0.038920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.205186</td>\n",
       "      <td>0.036962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.198535</td>\n",
       "      <td>0.033691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.191271</td>\n",
       "      <td>0.029345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.217773</td>\n",
       "      <td>0.029263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.215166</td>\n",
       "      <td>0.030645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.216776</td>\n",
       "      <td>0.025967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.190147</td>\n",
       "      <td>0.024995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.190309</td>\n",
       "      <td>0.025327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.174009</td>\n",
       "      <td>0.029201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.166262</td>\n",
       "      <td>0.022987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.186343</td>\n",
       "      <td>0.025415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.171746</td>\n",
       "      <td>0.025007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.180930</td>\n",
       "      <td>0.023354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.199248</td>\n",
       "      <td>0.026722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.174831</td>\n",
       "      <td>0.023668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.179675</td>\n",
       "      <td>0.024470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.185842</td>\n",
       "      <td>0.022880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.198168</td>\n",
       "      <td>0.020798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>0.167328</td>\n",
       "      <td>0.008683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>0.184747</td>\n",
       "      <td>0.008706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>0.165160</td>\n",
       "      <td>0.007781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>0.173523</td>\n",
       "      <td>0.008517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>0.171385</td>\n",
       "      <td>0.008327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>0.172876</td>\n",
       "      <td>0.008759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>0.171008</td>\n",
       "      <td>0.007731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>0.177720</td>\n",
       "      <td>0.008343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>0.172765</td>\n",
       "      <td>0.008565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>0.170179</td>\n",
       "      <td>0.008763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>0.169420</td>\n",
       "      <td>0.007338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>0.184577</td>\n",
       "      <td>0.007856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>0.173405</td>\n",
       "      <td>0.007725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>0.169099</td>\n",
       "      <td>0.007159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>0.161196</td>\n",
       "      <td>0.008016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>0.167060</td>\n",
       "      <td>0.008002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>0.175781</td>\n",
       "      <td>0.008002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>0.163966</td>\n",
       "      <td>0.007141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>0.172237</td>\n",
       "      <td>0.008557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>0.171859</td>\n",
       "      <td>0.007629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>0.170771</td>\n",
       "      <td>0.007978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>0.168587</td>\n",
       "      <td>0.008013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>0.171597</td>\n",
       "      <td>0.007914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>0.170038</td>\n",
       "      <td>0.008473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>0.181755</td>\n",
       "      <td>0.007809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.169289</td>\n",
       "      <td>0.008560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.183548</td>\n",
       "      <td>0.007859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.170391</td>\n",
       "      <td>0.008080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.169340</td>\n",
       "      <td>0.008572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.176915</td>\n",
       "      <td>0.007642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     val_loss      loss\n",
       "0    0.203225  0.264360\n",
       "1    0.237757  0.200286\n",
       "2    0.263508  0.139577\n",
       "3    0.314412  0.098040\n",
       "4    0.267303  0.099887\n",
       "5    0.244712  0.068521\n",
       "6    0.219361  0.064429\n",
       "7    0.206102  0.047933\n",
       "8    0.221745  0.043400\n",
       "9    0.252096  0.041663\n",
       "10   0.183848  0.044997\n",
       "11   0.203825  0.038920\n",
       "12   0.205186  0.036962\n",
       "13   0.198535  0.033691\n",
       "14   0.191271  0.029345\n",
       "15   0.217773  0.029263\n",
       "16   0.215166  0.030645\n",
       "17   0.216776  0.025967\n",
       "18   0.190147  0.024995\n",
       "19   0.190309  0.025327\n",
       "20   0.174009  0.029201\n",
       "21   0.166262  0.022987\n",
       "22   0.186343  0.025415\n",
       "23   0.171746  0.025007\n",
       "24   0.180930  0.023354\n",
       "25   0.199248  0.026722\n",
       "26   0.174831  0.023668\n",
       "27   0.179675  0.024470\n",
       "28   0.185842  0.022880\n",
       "29   0.198168  0.020798\n",
       "..        ...       ...\n",
       "970  0.167328  0.008683\n",
       "971  0.184747  0.008706\n",
       "972  0.165160  0.007781\n",
       "973  0.173523  0.008517\n",
       "974  0.171385  0.008327\n",
       "975  0.172876  0.008759\n",
       "976  0.171008  0.007731\n",
       "977  0.177720  0.008343\n",
       "978  0.172765  0.008565\n",
       "979  0.170179  0.008763\n",
       "980  0.169420  0.007338\n",
       "981  0.184577  0.007856\n",
       "982  0.173405  0.007725\n",
       "983  0.169099  0.007159\n",
       "984  0.161196  0.008016\n",
       "985  0.167060  0.008002\n",
       "986  0.175781  0.008002\n",
       "987  0.163966  0.007141\n",
       "988  0.172237  0.008557\n",
       "989  0.171859  0.007629\n",
       "990  0.170771  0.007978\n",
       "991  0.168587  0.008013\n",
       "992  0.171597  0.007914\n",
       "993  0.170038  0.008473\n",
       "994  0.181755  0.007809\n",
       "995  0.169289  0.008560\n",
       "996  0.183548  0.007859\n",
       "997  0.170391  0.008080\n",
       "998  0.169340  0.008572\n",
       "999  0.176915  0.007642\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saireddyavs\\Anaconda3\\envs\\gpuu\\lib\\site-packages\\numpy\\core\\fromnumeric.py:56: FutureWarning: \n",
      "The current behaviour of 'Series.argmin' is deprecated, use 'idxmin'\n",
      "instead.\n",
      "The behavior of 'argmin' will be corrected to return the positional\n",
      "minimum in the future. For now, use 'series.values.argmin' or\n",
      "'np.argmin(np.array(values))' to get the position of the minimum\n",
      "row.\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "828"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.argmin(df[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "828"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(np.array(df[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss    828\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['loss']].idxmin() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>0.169029</td>\n",
       "      <td>0.006902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     val_loss      loss\n",
       "828  0.169029  0.006902"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['loss']==df['loss'][828]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      "val_loss    1000 non-null float64\n",
      "loss        1000 non-null float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 15.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.175964</td>\n",
       "      <td>0.011505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.011284</td>\n",
       "      <td>0.012496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.155158</td>\n",
       "      <td>0.006902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.169665</td>\n",
       "      <td>0.008526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.174155</td>\n",
       "      <td>0.009399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.179036</td>\n",
       "      <td>0.011047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.314412</td>\n",
       "      <td>0.264360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          val_loss         loss\n",
       "count  1000.000000  1000.000000\n",
       "mean      0.175964     0.011505\n",
       "std       0.011284     0.012496\n",
       "min       0.155158     0.006902\n",
       "25%       0.169665     0.008526\n",
       "50%       0.174155     0.009399\n",
       "75%       0.179036     0.011047\n",
       "max       0.314412     0.264360"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011504845455856644"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"loss\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17596382461970234"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"val_loss\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "val_loss    487\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"val_loss\"]].idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>0.155158</td>\n",
       "      <td>0.009319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     val_loss      loss\n",
       "487  0.155158  0.009319"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"val_loss\"]==df[\"val_loss\"][487]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = df[\"val_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15515779092927595"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>0.155158</td>\n",
       "      <td>0.009319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     val_loss      loss\n",
       "487  0.155158  0.009319"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"val_loss\"]==0.15515779092927595]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006901816320611217"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"loss\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\saireddyavs\\Anaconda3\\envs\\gpuu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\saireddyavs\\Anaconda3\\envs\\gpuu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\saireddyavs\\Anaconda3\\envs\\gpuu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model=load_model(\"Best_model_One/mymodel_best_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread('steering_wheel_image.jpg',0)\n",
    "rows,cols = img.shape\n",
    "\n",
    "smoothed_angle = 0\n",
    "\n",
    "i = 0\n",
    "from subprocess import call\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saireddyavs\\Anaconda3\\envs\\gpuu\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \n",
      "C:\\Users\\saireddyavs\\Anaconda3\\envs\\gpuu\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted steering angle: -16.286138698504768 degrees\n",
      "Predicted steering angle: -5.102702847775004 degrees\n",
      "Predicted steering angle: -17.174162328349393 degrees\n",
      "Predicted steering angle: -14.774153382317387 degrees\n",
      "Predicted steering angle: -16.858943975511426 degrees\n",
      "Predicted steering angle: -16.56294748254517 degrees\n",
      "Predicted steering angle: -17.699567800063452 degrees\n",
      "Predicted steering angle: -17.888769162714684 degrees\n",
      "Predicted steering angle: -18.690225267471273 degrees\n",
      "Predicted steering angle: -19.283510866704212 degrees\n",
      "Predicted steering angle: -17.13113725922019 degrees\n",
      "Predicted steering angle: -15.130025021095268 degrees\n",
      "Predicted steering angle: -15.032645306551103 degrees\n",
      "Predicted steering angle: -18.35076657326893 degrees\n",
      "Predicted steering angle: -19.978788265718368 degrees\n",
      "Predicted steering angle: -17.720264980795882 degrees\n",
      "Predicted steering angle: -17.420112317719674 degrees\n",
      "Predicted steering angle: -17.847624103154526 degrees\n",
      "Predicted steering angle: -17.648640202064545 degrees\n",
      "Predicted steering angle: -18.03329425800486 degrees\n",
      "Predicted steering angle: -17.453067980464986 degrees\n",
      "Predicted steering angle: -17.018615015286105 degrees\n",
      "Predicted steering angle: -16.750717920565283 degrees\n",
      "Predicted steering angle: -17.885973907796856 degrees\n",
      "Predicted steering angle: -17.283307043738905 degrees\n",
      "Predicted steering angle: -18.74519975255341 degrees\n",
      "Predicted steering angle: -17.848435188118465 degrees\n",
      "Predicted steering angle: -18.618328988720425 degrees\n",
      "Predicted steering angle: -17.60755149156504 degrees\n",
      "Predicted steering angle: -16.34009719294787 degrees\n",
      "Predicted steering angle: -17.661066023712092 degrees\n",
      "Predicted steering angle: -18.095498498323458 degrees\n",
      "Predicted steering angle: -17.69154232778869 degrees\n",
      "Predicted steering angle: -15.911342313084074 degrees\n",
      "Predicted steering angle: -15.928692701123198 degrees\n",
      "Predicted steering angle: -17.630905615884608 degrees\n",
      "Predicted steering angle: -17.531965203115096 degrees\n",
      "Predicted steering angle: -16.9839722958158 degrees\n",
      "Predicted steering angle: -17.975015668911727 degrees\n",
      "Predicted steering angle: -17.103266672311953 degrees\n",
      "Predicted steering angle: -17.753804624715233 degrees\n",
      "Predicted steering angle: -18.18552892932069 degrees\n",
      "Predicted steering angle: -17.929623939235114 degrees\n",
      "Predicted steering angle: -16.71466647457866 degrees\n",
      "Predicted steering angle: -16.443569436231684 degrees\n",
      "Predicted steering angle: -17.267734212431275 degrees\n",
      "Predicted steering angle: -17.011916307257618 degrees\n",
      "Predicted steering angle: -15.904903152244044 degrees\n",
      "Predicted steering angle: -15.983878922069609 degrees\n",
      "Predicted steering angle: -17.077675661039205 degrees\n",
      "Predicted steering angle: -15.936045399764717 degrees\n",
      "Predicted steering angle: -15.383986822361974 degrees\n",
      "Predicted steering angle: -15.562280372908695 degrees\n",
      "Predicted steering angle: -15.532927634950566 degrees\n",
      "Predicted steering angle: -16.301836180764752 degrees\n",
      "Predicted steering angle: -17.758181068425916 degrees\n",
      "Predicted steering angle: -16.41727662302172 degrees\n",
      "Predicted steering angle: -17.347237614370222 degrees\n",
      "Predicted steering angle: -15.559034325505646 degrees\n",
      "Predicted steering angle: -14.804803856217818 degrees\n",
      "Predicted steering angle: -14.786340147343981 degrees\n",
      "Predicted steering angle: -17.15785695925328 degrees\n",
      "Predicted steering angle: -16.361316883151808 degrees\n",
      "Predicted steering angle: -15.598681866090278 degrees\n",
      "Predicted steering angle: -19.949795820238958 degrees\n",
      "Predicted steering angle: -16.776814365836607 degrees\n",
      "Predicted steering angle: -16.120387082821484 degrees\n",
      "Predicted steering angle: -15.593680460070535 degrees\n",
      "Predicted steering angle: -15.825194844629996 degrees\n",
      "Predicted steering angle: -18.036220994064212 degrees\n",
      "Predicted steering angle: -20.984548988928378 degrees\n",
      "Predicted steering angle: -17.643273380924207 degrees\n",
      "Predicted steering angle: -17.968120592944597 degrees\n",
      "Predicted steering angle: -17.19774355645886 degrees\n",
      "Predicted steering angle: -17.73726873673463 degrees\n",
      "Predicted steering angle: -20.374006916757402 degrees\n",
      "Predicted steering angle: -20.797461569825266 degrees\n",
      "Predicted steering angle: -20.646044813662545 degrees\n",
      "Predicted steering angle: -19.258042798836527 degrees\n",
      "Predicted steering angle: -16.305852331996718 degrees\n",
      "Predicted steering angle: -20.130567021907098 degrees\n",
      "Predicted steering angle: -17.92413588223701 degrees\n",
      "Predicted steering angle: -17.737383142403228 degrees\n",
      "Predicted steering angle: -14.338585388756503 degrees\n",
      "Predicted steering angle: -20.90929054955859 degrees\n",
      "Predicted steering angle: -16.895324978125497 degrees\n",
      "Predicted steering angle: -18.2189405071931 degrees\n",
      "Predicted steering angle: -19.140828214942644 degrees\n",
      "Predicted steering angle: -18.454694731679844 degrees\n",
      "Predicted steering angle: -19.17465814190172 degrees\n",
      "Predicted steering angle: -15.592497129796831 degrees\n",
      "Predicted steering angle: -15.325646761566311 degrees\n",
      "Predicted steering angle: -16.433575161928665 degrees\n",
      "Predicted steering angle: -15.806408409317875 degrees\n",
      "Predicted steering angle: -11.798351805290489 degrees\n",
      "Predicted steering angle: -12.616008264984702 degrees\n",
      "Predicted steering angle: -18.810059228911854 degrees\n",
      "Predicted steering angle: -16.878439042949935 degrees\n",
      "Predicted steering angle: -15.006859634887013 degrees\n",
      "Predicted steering angle: -15.151376192440727 degrees\n",
      "Predicted steering angle: -16.82268591630241 degrees\n",
      "Predicted steering angle: -16.14399392414034 degrees\n",
      "Predicted steering angle: -15.43006327850288 degrees\n",
      "Predicted steering angle: -16.436964643304282 degrees\n",
      "Predicted steering angle: -16.49727179858091 degrees\n",
      "Predicted steering angle: -16.60195298534782 degrees\n",
      "Predicted steering angle: -18.672939766229263 degrees\n",
      "Predicted steering angle: -17.90648325832711 degrees\n",
      "Predicted steering angle: -20.414147938509565 degrees\n",
      "Predicted steering angle: -19.17306329273052 degrees\n",
      "Predicted steering angle: -18.997836497121135 degrees\n",
      "Predicted steering angle: -16.99493474943367 degrees\n",
      "Predicted steering angle: -12.961482648298531 degrees\n",
      "Predicted steering angle: -15.383346492127286 degrees\n",
      "Predicted steering angle: -16.08501524065728 degrees\n",
      "Predicted steering angle: -15.20728641343916 degrees\n",
      "Predicted steering angle: -15.122552794143274 degrees\n",
      "Predicted steering angle: -15.92563789901691 degrees\n",
      "Predicted steering angle: -15.506151585856824 degrees\n",
      "Predicted steering angle: -13.460579938876997 degrees\n",
      "Predicted steering angle: -15.422503966638969 degrees\n",
      "Predicted steering angle: -16.456155767324727 degrees\n",
      "Predicted steering angle: -13.439703465678852 degrees\n",
      "Predicted steering angle: -13.820016936401625 degrees\n",
      "Predicted steering angle: -13.474137864379472 degrees\n",
      "Predicted steering angle: -11.391228134528125 degrees\n",
      "Predicted steering angle: -11.176626152127263 degrees\n",
      "Predicted steering angle: -13.681915634025845 degrees\n",
      "Predicted steering angle: -11.73389957896131 degrees\n",
      "Predicted steering angle: -14.099207748915067 degrees\n",
      "Predicted steering angle: -13.424854634423244 degrees\n",
      "Predicted steering angle: -11.900090034298769 degrees\n",
      "Predicted steering angle: -14.211506304153831 degrees\n",
      "Predicted steering angle: -14.287557045467338 degrees\n",
      "Predicted steering angle: -12.98866509364789 degrees\n",
      "Predicted steering angle: -12.87853170837602 degrees\n",
      "Predicted steering angle: -11.864044564727672 degrees\n",
      "Predicted steering angle: -13.544164378845027 degrees\n",
      "Predicted steering angle: -14.517316071410104 degrees\n",
      "Predicted steering angle: -10.386065906644136 degrees\n",
      "Predicted steering angle: -6.556710956966379 degrees\n",
      "Predicted steering angle: -13.093245535124542 degrees\n",
      "Predicted steering angle: -13.594077693752189 degrees\n",
      "Predicted steering angle: -14.39003720377421 degrees\n",
      "Predicted steering angle: -13.1909906647893 degrees\n",
      "Predicted steering angle: -13.48451975191789 degrees\n",
      "Predicted steering angle: -13.015924378625412 degrees\n",
      "Predicted steering angle: -14.527137883436582 degrees\n",
      "Predicted steering angle: -14.299581593501145 degrees\n",
      "Predicted steering angle: -14.549088403881711 degrees\n",
      "Predicted steering angle: -13.16352647413668 degrees\n",
      "Predicted steering angle: -12.302465869814329 degrees\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted steering angle: -13.376693263038192 degrees\n",
      "Predicted steering angle: -13.9641783241185 degrees\n",
      "Predicted steering angle: -13.24150332879613 degrees\n",
      "Predicted steering angle: -11.95007591996586 degrees\n",
      "Predicted steering angle: -12.932256268840048 degrees\n",
      "Predicted steering angle: -13.979563325223953 degrees\n",
      "Predicted steering angle: -14.179153405602772 degrees\n",
      "Predicted steering angle: -16.25429123395229 degrees\n",
      "Predicted steering angle: -15.14266599370167 degrees\n",
      "Predicted steering angle: -14.611512917801043 degrees\n",
      "Predicted steering angle: -12.109186030454953 degrees\n",
      "Predicted steering angle: -15.918471323030275 degrees\n",
      "Predicted steering angle: -16.59045948452198 degrees\n",
      "Predicted steering angle: -14.028561394782331 degrees\n",
      "Predicted steering angle: -14.054608321182176 degrees\n",
      "Predicted steering angle: -18.714817363577904 degrees\n",
      "Predicted steering angle: -16.661664206619363 degrees\n",
      "Predicted steering angle: -16.268276046277894 degrees\n",
      "Predicted steering angle: -15.947619155313305 degrees\n",
      "Predicted steering angle: -16.82265005780927 degrees\n",
      "Predicted steering angle: -15.254706709299265 degrees\n",
      "Predicted steering angle: -11.611966188124597 degrees\n",
      "Predicted steering angle: -15.488765339324555 degrees\n",
      "Predicted steering angle: -14.05459124570925 degrees\n",
      "Predicted steering angle: -13.945159662374598 degrees\n",
      "Predicted steering angle: -13.895719338067462 degrees\n",
      "Predicted steering angle: -13.198551684200504 degrees\n",
      "Predicted steering angle: -12.59743868817873 degrees\n",
      "Predicted steering angle: -12.867494122677279 degrees\n",
      "Predicted steering angle: -11.703203001283981 degrees\n",
      "Predicted steering angle: -4.609807368962911 degrees\n",
      "Predicted steering angle: -12.274433919686949 degrees\n",
      "Predicted steering angle: -12.82725406318215 degrees\n",
      "Predicted steering angle: -14.8419344720933 degrees\n",
      "Predicted steering angle: -15.531028842361302 degrees\n",
      "Predicted steering angle: -18.905705782954126 degrees\n",
      "Predicted steering angle: -16.258618158791496 degrees\n",
      "Predicted steering angle: -15.408266437314078 degrees\n",
      "Predicted steering angle: -14.251602929676391 degrees\n",
      "Predicted steering angle: -11.128917280774724 degrees\n",
      "Predicted steering angle: -14.340028266218669 degrees\n",
      "Predicted steering angle: -13.623345054345693 degrees\n",
      "Predicted steering angle: -15.075163234134433 degrees\n",
      "Predicted steering angle: -12.566938478440038 degrees\n",
      "Predicted steering angle: -13.139265642204794 degrees\n",
      "Predicted steering angle: -11.74211971162742 degrees\n",
      "Predicted steering angle: -14.201185888317942 degrees\n",
      "Predicted steering angle: -13.860084533620212 degrees\n",
      "Predicted steering angle: -14.991191180931004 degrees\n",
      "Predicted steering angle: -14.159499536266061 degrees\n",
      "Predicted steering angle: -13.790940821104881 degrees\n",
      "Predicted steering angle: -12.775814200995491 degrees\n",
      "Predicted steering angle: -12.995917046999152 degrees\n",
      "Predicted steering angle: -13.826995682186086 degrees\n",
      "Predicted steering angle: -14.341756304078682 degrees\n",
      "Predicted steering angle: -15.614141999276601 degrees\n",
      "Predicted steering angle: -15.7561570000468 degrees\n",
      "Predicted steering angle: -12.857284697415404 degrees\n",
      "Predicted steering angle: -2.7295602373998316 degrees\n",
      "Predicted steering angle: -11.963508340742337 degrees\n",
      "Predicted steering angle: -15.243202963189672 degrees\n",
      "Predicted steering angle: -14.823002895261318 degrees\n",
      "Predicted steering angle: -14.975387830738887 degrees\n",
      "Predicted steering angle: -13.121148565431335 degrees\n",
      "Predicted steering angle: -13.412252935404572 degrees\n",
      "Predicted steering angle: -16.131882291194614 degrees\n",
      "Predicted steering angle: -15.98684663926398 degrees\n",
      "Predicted steering angle: -14.802199846596752 degrees\n",
      "Predicted steering angle: -13.549218718830836 degrees\n",
      "Predicted steering angle: -12.748182670708204 degrees\n",
      "Predicted steering angle: -12.69809006333533 degrees\n",
      "Predicted steering angle: -11.880638509316219 degrees\n",
      "Predicted steering angle: -12.061893800641785 degrees\n",
      "Predicted steering angle: -12.075075211966263 degrees\n",
      "Predicted steering angle: -14.061110661272028 degrees\n",
      "Predicted steering angle: -12.557447930588305 degrees\n",
      "Predicted steering angle: -10.007303742636603 degrees\n",
      "Predicted steering angle: -15.415735249171487 degrees\n",
      "Predicted steering angle: -14.636542146014554 degrees\n",
      "Predicted steering angle: -17.02124976075844 degrees\n",
      "Predicted steering angle: -19.379469901901015 degrees\n",
      "Predicted steering angle: -14.154421290618156 degrees\n",
      "Predicted steering angle: -14.844412123214722 degrees\n",
      "Predicted steering angle: -15.572184147205213 degrees\n",
      "Predicted steering angle: -14.950829885578106 degrees\n",
      "Predicted steering angle: -14.93776885633775 degrees\n",
      "Predicted steering angle: -12.696495214164132 degrees\n",
      "Predicted steering angle: -14.488188729694585 degrees\n",
      "Predicted steering angle: -13.85222469343282 degrees\n",
      "Predicted steering angle: -13.203781901557441 degrees\n",
      "Predicted steering angle: -14.827326405005936 degrees\n",
      "Predicted steering angle: -15.77119878414646 degrees\n",
      "Predicted steering angle: -15.417910664422136 degrees\n",
      "Predicted steering angle: -15.690921863284007 degrees\n",
      "Predicted steering angle: -13.42697370061324 degrees\n",
      "Predicted steering angle: -17.63242191788035 degrees\n",
      "Predicted steering angle: -16.056027917819748 degrees\n",
      "Predicted steering angle: -15.405568512591923 degrees\n",
      "Predicted steering angle: -12.723725470837682 degrees\n",
      "Predicted steering angle: -14.908759335385412 degrees\n",
      "Predicted steering angle: -14.65932936463301 degrees\n",
      "Predicted steering angle: -18.413329398518954 degrees\n",
      "Predicted steering angle: -18.409572794475448 degrees\n",
      "Predicted steering angle: -16.950779283996834 degrees\n",
      "Predicted steering angle: -16.61651665620558 degrees\n",
      "Predicted steering angle: -18.505726490063594 degrees\n",
      "Predicted steering angle: -19.048403802641324 degrees\n",
      "Predicted steering angle: -21.335354334889402 degrees\n",
      "Predicted steering angle: -16.6499709227603 degrees\n",
      "Predicted steering angle: -17.367538644130793 degrees\n",
      "Predicted steering angle: -14.238326749477178 degrees\n",
      "Predicted steering angle: -14.822651140519062 degrees\n",
      "Predicted steering angle: -13.79330065146312 degrees\n",
      "Predicted steering angle: -14.287413611494767 degrees\n",
      "Predicted steering angle: -19.4638842098532 degrees\n",
      "Predicted steering angle: -13.509975866954528 degrees\n",
      "Predicted steering angle: -12.110119205050307 degrees\n",
      "Predicted steering angle: -2.963163379184846 degrees\n",
      "Predicted steering angle: -11.6721879660366 degrees\n",
      "Predicted steering angle: -10.0369032211785 degrees\n",
      "Predicted steering angle: -10.55761464538547 degrees\n",
      "Predicted steering angle: -8.437639186455757 degrees\n",
      "Predicted steering angle: -7.143563371774814 degrees\n",
      "Predicted steering angle: -7.869246211652927 degrees\n",
      "Predicted steering angle: -6.359212622020875 degrees\n",
      "Predicted steering angle: -6.405108078148777 degrees\n",
      "Predicted steering angle: -6.269498087272758 degrees\n",
      "Predicted steering angle: -6.044902684342521 degrees\n",
      "Predicted steering angle: -5.665020369311105 degrees\n",
      "Predicted steering angle: -5.820068224791334 degrees\n"
     ]
    }
   ],
   "source": [
    "while(cv2.waitKey(20) != ord('q')):\n",
    "    full_image = scipy.misc.imread(\"driving_dataset/driving_dataset/\" + str(i) + \".jpg\", mode=\"RGB\")\n",
    "    image = scipy.misc.imresize(full_image[-150:], [66, 200]) / 255.0\n",
    "    degrees = model.predict(image[None,...])[0][0] * 180.0 / scipy.pi\n",
    "    #call(\"clear\")\n",
    "    print(\"Predicted steering angle: \" + str(degrees) + \" degrees\")\n",
    "    cv2.imshow(\"frame\", cv2.cvtColor(full_image, cv2.COLOR_RGB2BGR))\n",
    "    #make smooth angle transitions by turning the steering wheel based on the difference of the current angle\n",
    "    #and the predicted angle\n",
    "    smoothed_angle += 0.2 * pow(abs((degrees - smoothed_angle)), 2.0 / 3.0) * (degrees - smoothed_angle) / abs(degrees - smoothed_angle)\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2),-smoothed_angle,1)\n",
    "    dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "    cv2.imshow(\"steering wheel\", dst)\n",
    "    i += 1\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpuu",
   "language": "python",
   "name": "gpuu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
